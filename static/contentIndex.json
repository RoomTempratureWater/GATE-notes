{"CLANG/C-language":{"slug":"CLANG/C-language","filePath":"CLANG/C language.md","title":"C language","links":[],"tags":[],"content":"\nIntroduction to C Language - Part-1 | C Language Tutorial\n\n\nIntroduction to C Language - Part-2 | C Language Tutorial\n\n\nSyllabus of c language\n\n\nkeywords in C language\n\n\nvariable and constant in C\n\n\nDataTypes in c | what are data types | DataTypes in c programming\n\n\nOperators in C | Arithmetic operator in C | Assignment | relational | logical operators in C\n\n\noperators in C | Increment operator in C | Decrement operator in C\n\n\noperators in C |  Ternary (conditional) operator in C |  Sizeof operator in C | Shortcut  operators\n\n\noperators in C |  Type casting operator in C |  Type conversion in C | implicit and explicit\n\n\noperators in C |  comma operator in C |  comma as a separator | comma as a operator\n\n\nRules for Naming a Variable| How to Write Variable Name| Variable Naming Conventions In C Language\n\n\ninput output functions in C program | printf, scanf | printf and scanf functions c langauge\n\n\nfirst c program\n\n\nSimple if Statement in C | control structures in C\n\n\nIf Else Control Statements In C: C Tutorial In Hindi\n\n\nnested if statement in c programming | nested if statement syntax,flowchart and example program in c\n\n\nif else if ladder statement in c | else if statement syntax, flowchart and example program in c\n\n\nSwitch Case Control Statements In C: C Tutorial In Hindi | part 1\n\n\nSwitch Case Control Statements In C: C Tutorial In Hindi | part 2\n\n\nWhile Loop In C: C Tutorial In Hindi\n\n\nDo While Loop In C: C Tutorial In Hindi\n\n\nFor Loop In C: C Tutorial In Hindi\n\n\nNested Loops in C\n\n\nbreak and continue statements  In C\n\n\nPrinting Patterns In C | PART 1\n\n\nPrinting Patterns In C | PART 2\n\n\nPrinting Patterns In C | PART 3\n\n\n2 D Arrays In C: C Tutorial In Hindi\n\n\nArrays In C: C Tutorial In Hindi\n\n\n2 D Arrays In C: C Tutorial In Hindi | part 2\n\n\nStrings In C: C Tutorial In Hindi | GATE 2023 | PART 1\n\n\nStrings In C: C Tutorial In Hindi | GATE 2023 | PART 2\n\n\nFunctions In C: C Tutorial In Hindi | part 1\n\n\nFunctions In C: C Tutorial In Hindi | part 2\n\n\nRecursive Functions: Recursion In C: C Tutorial In Hindi | PART 1\n\n\nRecursive Functions: Recursion In C: C Tutorial In Hindi | PART 2\n\n\nRecursive Functions: Recursion In C: C Tutorial In Hindi | PART 3\n\n\nRecursive Functions: Recursion In C: C Tutorial In Hindi | PART 4\n\n\nRecursive Functions: Recursion In C: C Tutorial In Hindi | PART 5\n\n\nStorage Classes In C Auto, Extern, Static &amp; Register Storage Classes: C Tutorial In Hindi | part 1\n\n\nStorage Classes In C Auto, Extern, Static &amp; Register Storage Classes: C Tutorial In Hindi | part 2\n\n\nStorage Classes In C Auto, Extern, Static &amp; Register Storage Classes: C Tutorial In Hindi | part 3\n\n\nStorage Classes In C Auto, Extern, Static &amp; Register Storage Classes: C Tutorial In Hindi | part 4\n\n\nStorage Classes In C Auto, Extern, Static &amp; Register Storage Classes: C Tutorial In Hindi | part 5\n\n\nC Pre-processor Introduction &amp; Working: C Tutorial In Hindi\n\n\nUser Defined Datatypes in C Language | C Tutorial for Beginners\n\n\nBitwise operators in C\n\n\nC language completed!! | GATE 2023\n\n\n1. Pointers intro 1\n\n\n2. Pointers intro 2\n\n\n3. Summary of intro to pointers\n\n\n4. pointer to pointer\n\n\n5. small question on pointers\n\n\n6. practice question for * and &amp; operator\n\n\n7. pointer arithmetic\n\n\n8. question on pointer arithmetic\n\n\n9. void pointer\n\n\n10. question on void pointer\n\n\nhow to print content of memory location 2000\n\n\npointer and pointer to pointer diffrence\n\n\ncomplex pointers\n\n\nquestion on complex pointers\n\n\ngate 2005 question on complex pointer\n\n\npointer and function\n\n\ncall by value and call by refrence\n\n\ngate 2016 question on call by refrence\n\n\ngate 2016 and 2017 question on pointer and function\n\n\ngate 2008 and 2010 question on pointer and function\n\n\npointer and 1D array\n\n\nquestion on pointer and 1d array\n\n\nquestion explaining difference between pointer to an array and array of pointers.\n\n\nbeautiful question on pointer and 1D array\n\n\nanother important question on pointer and 1D array\n\n\ngate 2015 and gate 2019 question on pointer and 1d array\n\n\npointer and 2D array part 1\n\n\npointer and 2D array part 2\n\n\ngate 2006 question on pointer and array\n\n\npointer and 3D array\n\n\npointer and string part1\n\n\npointer and string part 2\n\n\nquestion on pointer and string\n\n\nvery important question on pointer and string\n\n\nGATE 2011 and GATE 2015 questions on pointer and strings\n\n\npointer and structure\n\n\nGate 2006 question on pointer and structure\n\n\nDynamic memory allocation\n\n\nDangling pointers.\n"},"CLANG/Storage-classes":{"slug":"CLANG/Storage-classes","filePath":"CLANG/Storage classes.md","title":"Storage classes","links":[],"tags":[],"content":"a storage class defines 4 properties of a variable/function?:\n\nwhere its stored\ndefault value\nscope\nlifetime\n\nand there are 4 main types of storage classes\n\nAuto class\nStatic\nRegister\nExternal\n\nQUICK NOTES:\n\ndefault storage class of global variables is extern\ndefault storage class of local variables is auto\n\n\nAuto Class"},"CN/2D-parity-check-code":{"slug":"CN/2D-parity-check-code","filePath":"CN/2D parity check code.md","title":"2D parity check code","links":[],"tags":[],"content":"\nData words are organised in a table (row and columns) (2D matrix)\nFor each row and column, one parity check bit is calculated\nIt guarantees to correct one-bit errors and detect upto 3 bit errors\n\nEx below: lets assume we are sending 4 datawords of 7 bits each\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 0 1 1 0 1 001 1 1 1 1 0 101 0 1 0 0 0 111 0 1 1 0 1 110 1 0 1 1 0 10we are making each datawords even (like [[CN/Simple Parity Check CodeSimple Parity Check Code]])\nDisadvantage of this is that error can obviously also be in the parity bits and therefore it isn’t used much in  computer networks nowadays"},"CN/Bit-rate-vs-Baud-Rate":{"slug":"CN/Bit-rate-vs-Baud-Rate","filePath":"CN/Bit rate vs Baud Rate.md","title":"Bit rate vs Baud Rate","links":[],"tags":[],"content":"signal element\none signal element is one signal with constant amplitude\nBit Rate\nNo of bits transmitted per sec\nBaud Rate\nNo of signal elements transferred per sec\n"},"CN/Data-link-Layer":{"slug":"CN/Data-link-Layer","filePath":"CN/Data-link Layer.md","title":"Data-link Layer","links":["tags/cn","tags/datalinklayer","tags/computernetworks"],"tags":["cn","datalinklayer","computernetworks"],"content":"cn datalinklayer computernetworks\nThe Data Link Layer is the second layer of the OSI model, responsible for facilitating communication between adjacent network nodes. It provides several key functions to ensure reliable and efficient data transfer, including:\n\n\nFraming: It organizes data into frames, which include the data payload and necessary control information, such as error detection codes.\n\n\nError Detection and Correction: The Data Link Layer detects and, in some cases, corrects errors that may occur during data transmission. It uses techniques like checksums and cyclic redundancy checks (CRC) to identify errors.\n\n\nFlow Control: This mechanism ensures that the sender does not overwhelm the receiver with too much data too quickly. It manages the rate of data transmission between devices.\n\n\nMedium Access Control (MAC): The MAC sublayer manages access to the physical transmission medium, determining how devices share the medium and when they can transmit data.\n\n\nAddressing: The Data Link Layer uses MAC addresses to uniquely identify devices on a local network, facilitating proper delivery of frames to their intended destination.\n\n\nThe Data Link Layer plays a crucial role in providing a reliable link between devices in a network, managing data flow, error handling, and ensuring proper communication between adjacent nodes."},"CN/Delay":{"slug":"CN/Delay","filePath":"CN/Delay.md","title":"Delay","links":[],"tags":[],"content":"Types of Network Delay in Physical Layer\n\nPropagation Delay (Tp): The time it takes for a signal to travel from the sender to the receiver over the medium. This delay depends on the distance between the two points and the speed at which the signal travels through the medium.\nTransmission Delay (Tt): The time required to push all the bits of the packet onto the medium. It depends on the packet size and the data transmission rate (bandwidth) of the medium.\nProcessing Delay: The time it takes for network devices (such as switches, routers, or hubs) to process the packet headers and make forwarding decisions.\nQueuing Delay: The time a packet spends waiting in a queue before it can be transmitted. This delay can vary depending on network congestion and the device’s handling capacity. 5.\nJitter: The variation in the time it takes for packets to travel from the sender to the receiver. Jitter can be caused by changes in the queuing and processing delays.\n\nFormulae\n\n(Tt) = packet or data size / bandwidth\n(Tp) = distance between hosts / speed of wave or signal\n"},"CN/Error-Checking-and-correction":{"slug":"CN/Error-Checking-and-correction","filePath":"CN/Error Checking and correction.md","title":"Error Checking and correction","links":[],"tags":[],"content":"Error checking is more efficient than error correction, if an error is found, we just ask to send that data again\nLogic for error checking\nIn most error checking algorithms, we add some Redundant bits to the data.\nso for example,\n10111 can be sent as 10111 0 with the last bit as the redundant bit or a parity bit\nwe can then use this parity bit to determine the error\nHamming Distance\nhamming distance is the difference in bits between 2 binary strings\nso d(101, 100) = 1 since only 1 bit is different\nP.S →  the size of the strings has to be same for comparison, add 0’s infront to make them equal in size.\nhamming distance can be calculated by doing an XOR operation on the strings and then count the number of 1’s in the result\n(XOR = dono different = 1, dono same = 0)\n2 Hamming distance means there is  bits which are different\nMinimum Hamming distance to detect T bit errors\nIf data word is of length 2, and code word is of length 3, so we have one extra redundant bit so we can detect one bit errors, so:\nIf we want to detect T bits of error, then the  minimum Hamming distance should be T+1"},"CN/Linear-block-codes":{"slug":"CN/Linear-block-codes","filePath":"CN/Linear block codes.md","title":"Linear block codes","links":["CN/Simple-Parity-Check-Code","CN/2D-parity-check-code","Cyclic-code","Check-sum"],"tags":[],"content":"If XOR of 2 codewords is an valid codeword, then we can say the codewords are linear block codes\n(code word is basically a data word and then added some parity/redundants bits to it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDWCDW00000010111010111110\nsince xor of 000 and 011 gives 011\nand XOR(011, 101) = 110\netc.\nwe can say these codewords are linear block codes\nTypes of linear block codes\n\nSimple Parity Check Code\n2D parity check code\nCyclic code\nCheck sum\n\n\n"},"CN/Manchester-and-Differential-manchester":{"slug":"CN/Manchester-and-Differential-manchester","filePath":"CN/Manchester and Differential manchester.md","title":"Manchester and Differential manchester","links":[],"tags":[],"content":"\nAdvantages:\n\nSynchronization problem is solved\nDC component is zero\n\nDifferential Manchester\n0 ⇒ No change in shape\n1 ⇒ Change in shape\n"},"CN/Multiplexing":{"slug":"CN/Multiplexing","filePath":"CN/Multiplexing.md","title":"Multiplexing","links":[],"tags":[],"content":"Types of multiplexing\n\nFrequency division multiplexing (FDM)\nTime division multiplexing (TDM)\nWavelength division multiplexing (WDM)\n\nonly TDM in syllabus"},"CN/NRZ":{"slug":"CN/NRZ","filePath":"CN/NRZ.md","title":"NRZ","links":[],"tags":[],"content":"unipolar NRZ\n1 ⇒ positive level\n0 ⇒ negative level\n\nDisadvantages:\n\nwe want DC component to be 0 (whose net power is 0)\nsync of continous 0 or 1 is a problem\n\npolar NRZ\nNRZ - L\n1 ⇒ +ve level, 0 ⇒ -ve level or vice versa\n\nDisadvantages:\n\nDC component non zero\nsync of continous bits is not possible\n\nNRZ - I\n\n1 → change in leve\n0 → no change in level\n\n\nDisadvantages:\nDC component non zero\nsync of continous bits is a problem\n4B/5B\n"},"CN/Physical-Layer":{"slug":"CN/Physical-Layer","filePath":"CN/Physical Layer.md","title":"Physical Layer","links":["tags/cn","tags/physicallayer","tags/computernetworks"],"tags":["cn","physicallayer","computernetworks"],"content":"cn physicallayer computernetworks\nThe physical layer is the first and lowest layer in the OSI (Open Systems Interconnection) model. It is responsible for the physical connection between devices, including the transmission and reception of raw bitstreams over a physical medium. This layer deals with the hardware aspects of networking, such as cables, switches, and other transmission mediums. Key functions of the physical layer include:\n\nData Encoding and Signaling: Converting data into signals suitable for the transmission medium.\nTransmission and Reception: Sending and receiving raw bits across the network.\nPhysical Medium: Handling the physical connection methods, like electrical signals over copper wires, light signals over fiber optics, or radio signals in wireless communications.\nTopology and Layout: Defining the physical structure of the network, such as star, ring, or bus topologies.\nBit Rate Control: Managing the rate of data transmission in bits per second.\n\nOverall, the physical layer ensures that the raw data is transmitted over a physical medium, forming the foundation for higher layers to build upon."},"CN/RZ":{"slug":"CN/RZ","filePath":"CN/RZ.md","title":"RZ","links":[],"tags":[],"content":"Return to Zero\n1 → Z\n2 → ulta Z\n\nAdvantage:\nsynchronization problem is solved because level is returned to zero each time\nDisadvantage:\nDC component isnt zero,\nit is zero in only some cases"},"CN/Signal-Encoding-Techniques":{"slug":"CN/Signal-Encoding-Techniques","filePath":"CN/Signal Encoding Techniques.md","title":"Signal Encoding Techniques","links":["CN/digital-to-digital"],"tags":[],"content":"Channels are of 2 types:\n\nbase band\nbroadband\n\nBaseband:\n\nits like a railway track so only one signal can pass at a given time\ndigital signal\ncollision can occur\nBroadband:\nits like a highway, can carry multiple signals at once\nanalog signal\nno collision\n\ntypes of encoding:\n\ndigital to digital signal\nDigital to Analog\nAnalog to Digital\nAnalog to Analog\n\nattenuation: loss of power during signal travel"},"CN/Simple-Parity-Check-Code":{"slug":"CN/Simple-Parity-Check-Code","filePath":"CN/Simple Parity Check Code.md","title":"Simple Parity Check Code","links":[],"tags":[],"content":"\nOne extra bit is added (parity bit) to the data word to make the TOTAL NUMBER OF 1’s EVEN\nit can detect odd number of errors\nCANNOT detect even number of errors since Even number of erros can make it look like there is no error\nMinimum Hamming distance is 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDWCW00000010111010111110can also put the bit in the end of beginning"},"CN/TDM":{"slug":"CN/TDM","filePath":"CN/TDM.md","title":"TDM","links":[],"tags":[],"content":"Synchronous TDM\nNo of slots = no of stations\nIf station doesnt send data, slot will be empty\n\nAsynchronous TDM\nNo of slots &lt; no of stations\nIf all stations want to send data simultaneously, there will be backlogs\n\nEfficiency of TDM = Tt / ( Tp + Tt)"},"CN/computer-networks":{"slug":"CN/computer-networks","filePath":"CN/computer networks.md","title":"computer networks","links":[],"tags":[],"content":"\nComputer Network Detailed Syllabus topic wise | Gate CSE\n\n\n1. intro to computer networks\n\n\n2. osi model in hindi\n\n\n3. Physical layer in computer networks in hindi | Functions of Physical layer | OSI\n\n\n4. types of addresses in networking\n\n\n5. Data link layer in computer Networks and its Responsibilities\n\n\n6. Network Layer | Responsibilities of Network Layer | OSI Model | Computer Networks\n\n\n7. Transport Layer | Responsibilities of Transport Layer | OSI Model | Computer Networks\n\n\n8. Session Layer of OSI model | Session layer functions in Hindi\n\n\n9. functions of presentation and application layer|osi model\n\n\n10. why OSI model failed\n\n\n11. intro to TCP/IP model\n\n\n12. introduction to IP\n\n\n13. supporting protocols of IP\n\n\n14. INTRO TO TRANSPORT LAYER PROTOCOLS\n\n\n15. introduction to signals\n\n\n16. simple analog signals\n\n\n17. composite analog signals\n\n\n18. digital signals\n\n\n19. signal encoding techniques\n\n\n20. Digital data to Digital signal conversion\n\n\n21. unipolar NRZ\n\n\n22. polar NRZ L and NRZ I\n\n\n23. gate 2006 question on 4B/5B scheme\n\n\n24. RZ technique\n\n\n25. manchester encoding and differential manchester encoding\n\n\n26. gate 2007 question on mechester encoding\n\n\n27. bit rate and baud rate\n\n\n28. serial vs parallel transmission\n\n\n29. gate 2004 question on serial transmission\n\n\n30. gate 2004 question 2 on serial transmission\n\n\n31. gate 2008 question on serial transmission\n\n\n32. BW ,THROUGHPUT AND DELAY\n\n\n33. numerical on delay\n\n\n34. gate 2015 question on delay\n\n\n35. intro to multiplexing\n\n\n36. introduction to FDM and WDM\n\n\n37. introduction to TDM\n\n\n38.  gate 2007 question on TDM\n\n\n39. gate 2005 question on TDM\n\n\n40. ERROR DETECTION VS CORRECTION\n\n\n41. logic for error detection\n\n\n42. hamming distance\n\n\n43. minimum hamming distance to detect t bit error\n\n\n44. linear block codes\n\n\n45. simple parity check code\n\n\n46. 2D parity check code\n\n\n47. gate 2008 question on 2d parity check code\n\n\n48. cyclic codes\n\n\n49. introduction to CRC\n\n\n50. polynomial notation in CRC\n\n\n51. choosing divisor in CRC\n\n\n52. gate 2005 question on CRC\n\n\n53. gate 2007 question on CRC\n\n\n54(1). checksum\n\n\n54(2). hamming codes\n\n\n54(3). GATE 2021 question on hamming codes\n\n\n55. framing\n\n\n56. flow and error control\n\n\n57. stop and wait\n\n\n58. question on stop and wait\n\n\n59. gate 2006 question on stop and wait\n\n\n60. efficiency and throughput of stop and wait\n\n\n61. piggybacking\n\n\n62. gate 2005 &amp; 2015 question on stop and wait\n\n\n63. gate 2015 question on stop and wait\n\n\n64. gate 2016 question on stop and wait\n\n\n65. gate 2017 question on stop and wait\n\n\n66. capacity of link\n\n\n67. sliding window protocol\n\n\n68. gate 2003 question on sliding window protocol\n\n\n69. gate 2006 question on sliding window protocol\n\n\n70. gate 2007 question on sliding window protocol\n\n\n71. gate 2009 question on sliding window protocol\n\n\n72. implementation of sliding window protocol\n\n\n73. go back n ARQ\n\n\n74. gate 2004 question on gbn\n\n\n75. gate 2004 question on GBN\n\n\n76. gate 2008 question on gbn\n\n\n77. gate 2006 question on gbn\n\n\n78. gate 2015 question on gbn\n\n\n79. selective repeat ARQ protocol\n\n\n80. gate 2016 question on selective repeat\n\n\n81. gate 2012 question on pipelining\n\n\n82. multiple access protocols\n\n\n85. vulnerable time of aloha\n\n\n83. random access protocols\n\n\n84. aloha\n\n\n86. throughput of aloha\n\n\n87. slotted aloha\n\n\n88. gate 2007 question on slotted LAN\n\n\n89. gate 2015 question on slotted LAN\n\n\n90. csma introduction\n\n\n91. persistence methods in csma\n\n\n92. csma/cd\n\n\n93. NUMERICALS ON CSMA CD\n\n\n98. CSMA/CA\n\n\n94. gate 2004 question on csma\n\n\n95. gate 2013 and 2015 question on csma\n\n\n96. gate 2018 question on csma\n\n\n97. efficiency of csma\n\n\n99. controlled access protocols\n\n\n100. reservation\n\n\n101. polling\n\n\n102. gate 2007 question on polling\n\n\n103. token passing\n\n\n104. ethernet introduction\n\n\n105. ethernet frame format\n\n\n106. connecting devices\n\n\n107. passive hub\n\n\n108. repeater and hub\n\n\n109. bridge\n\n\n110. switching techniques in networking(circuit switching, message switching, packet switching)\n\n\n111. layer 2 switch\n\n\n112. router and layer 3 switch\n\n\n113. gateway\n\n\n114. broadcast domain and collision domain\n\n\n115. introduction to IP addressing\n\n\n116. introduction to class full addressing\n\n\n117. concept of net mask\n\n\n118. subnetting part 1\n\n\n119. subnetting part 2\n\n\n120. practice questions on subnetting (part 1)\n\n\n121. practice questions on subnetting part 2\n\n\n122. practice questions on subnetting part 3\n\n\n123. subnetting (part 3) vlsm\n\n\n124. supernetting\n\n\n125. gate 2003,2004,2005 questions on IP addressing\n\n\n126. gate 2006,2007,2010,2019 questions on IP addressing\n\n\n127. class less addressing introduction\n\n\n128. subnetting in class less addressing\n\n\n129. Supernetting in class less addressing\n\n\ngate 2006,2008,2012 questions on IP addressing\n\n\nspecial addresses in ipv4 addressing scheme\n\n\nipv4 header part 1\n\n\nipv4 header part 2\n\n\nFragmentation of IPv4 Datagram | GATE 2023 | Part 1\n\n\nFragmentation of IPv4 Datagram | GATE 2023 | Part 2| Identification | flags | fragmentation offset\n\n\nFragmentation of IPv4 Datagram | practice questions | GATE 2023 | Part 3\n\n\nFragmentation of IPv4 Datagram | Actual Process | GATE 2023 | Part 4\n\n\nFragmentation of IPv4 Datagram | Few important questions | GATE 2023 | Part 5\n\n\nOption in IPv4 - Internetworking Layer | IPV4 OPTIONS | GATE 2023\n\n\nARP Explained- Address Resolution Protocol | Network Layer\n\n\nReverse Address Resolution Protocol RARP Protocol in Computer Networks | GATE 2023\n\n\nWhat is ICMP ? | Internet Control Message Protocol (in Hindi) | Part 1 | GATE 2023\n\n\nWhat is ICMP ? | Internet Control Message Protocol (in Hindi) | Part 2 | GATE 2023\n\n\nDelivery forwarding and routing | network layer | GATE 2023 | PART 1\n\n\nDelivery forwarding and routing | network layer | GATE 2023 | PART 2\n\n\nDelivery forwarding and routing | network layer | GATE 2023 | PART 3\n\n\nDelivery forwarding and routing | network layer | GATE 2023 | PART 4 | decreasing size of R.T.\n\n\nDelivery forwarding and routing | network layer | GATE 2023 | PART 5 | Routing algorithms\n\n\nDistance vector routing algorithm in hindi | Computer Networks | part 1 | GATE 2023\n\n\nDistance vector routing algorithm in hindi | Computer Networks | part 2 | GATE 2023\n\n\nDistance vector routing algorithm in hindi | Computer Networks | part 3 | GATE QUESTIONS\n\n\nDistance vector routing algorithm in hindi | Computer Networks | part 4 | Count to infinity problem\n\n\nDistance vector routing algorithm | Computer Networks | part 5 | Count to infinity problem solution\n\n\nLink state routing in computer networks in Hindi (PART 1)| GATE 2023\n\n\nLink state routing in computer networks in Hindi (PART 2)| GATE 2023\n\n\nIntroduction to transport layer | Transport Layer | GATE 2023\n\n\nUDP | User datagram protocol | PART 1(INTRODUCTION) | GATE 2023\n\n\nUDP | User datagram protocol | PART 2(UDP HEADER) | GATE 2023\n\n\nUDP | User datagram protocol | PART 3(WORKING AND USES) | GATE 2023\n\n\nTCP: Transmission control protocol | TCP Header | Transport layer | part -1\n\n\nTCP: Transmission control protocol | TCP SEQUENCE NUMBER  | Transport layer | part -2\n\n\nTCP: Transmission control protocol | TCP wrap around time  | Transport layer | part -2\n\n\nTCP: Transmission control protocol | TCP Header | Transport layer | part -4\n\n\nTCP: Transmission control protocol | TCP connection establishment | Transport layer | part -5\n\n\nTCP: Transmission control protocol | TCP data tranfer | Transport layer | part -6\n\n\nTCP: Transmission control protocol | TCP connection termination | Transport layer | part -7\n\n\nTCP: Transmission control protocol | TCP state transition diagram | Transport layer | part -8\n\n\nTCP: Transmission control protocol | TCP state transition diagram | Transport layer | part -9\n\n\nTCP: Transmission control protocol | TCP state transition diagram | Transport layer | part -10\n\n\nTCP: Transmission control protocol | TCP state transition diagram | Transport layer | part -11\n\n\nTCP: Transmission control protocol | TCP state transition diagram | Transport layer | part -12\n\n\nTCP: Transmission control protocol | TCP system calls | Transport layer | part -13\n\n\nTCP: Transmission control protocol | TCP system calls | Transport layer | part -14\n\n\nTCP: Transmission control protocol | TCP push flag | PSH | Transport layer | part -15\n\n\nTCP: Transmission control protocol | TCP URG and RST flag | Transport layer | part -16\n\n\nTCP: Transmission control protocol | TCP flow control | Transport layer | part -17\n\n\nTCP: Transmission control protocol | TCP options | Transport layer | part -18\n\n\nTCP: Transmission control protocol | TCP retransmission | Transport layer | part -19\n\n\nLeaky Bucket Algorithm In Hindi | Congestion Control In Hindi | Leaky Bucket | Part 1\n\n\nLeaky Bucket Algorithm In Hindi | Congestion Control In Hindi | Leaky Bucket | Part 2\n\n\nToken Bucket Algorithm In Hindi | Congestion Control In Hindi | Token Bucket\n\n\nTCP CONGESTION CONTROL | AIMD | Additive Increase Multiplicative Decrease | part 1\n\n\nTCP CONGESTION CONTROL | AIMD | Additive Increase Multiplicative Decrease | part 2\n\n\nTCP CONGESTION CONTROL | AIMD | Additive Increase Multiplicative Decrease | part 3\n\n\nTCP TIMERS | GATE 2023 | part 1\n\n\nTCP TIMERS | GATE 2023 | part 2\n\n\nTCP TIMERS | GATE 2023 | part 3\n\n\nSILLY WINDOW SYNDROME IN TCP | NEGAL’S SOLUTION | CLARK’S SOLUTION\n\n\nDomain Name System (DNS) in computer Networks | part 1\n\n\nDomain Name System (DNS) in computer Networks | part 2\n\n\nDomain Name System (DNS) in computer Networks | part 3(DNS working)\n\n\nEMAIL (Part -I) | Computer Networks\n\n\nEMAIL (Part -2) | Computer Networks\n\n\nEMAIL (Part -3) | Computer Networks\n\n\nFTP | FILE TRANSFER PROTOCOL | Computer Networks | GATE 2023\n\n\nFTP | FILE TRANSFER PROTOCOL | Computer Networks | GATE 2023 | PART 2\n\n\nHTTP | Hyper text transfer protocol | computer networks | GATE 2023\n\n\nApplication Layer Most Important Points | GATE PYQs of APPLICATION LAYER | GATE 2023\n\n\nFinally Computer Networks Completed | GATE 2023\n"},"CN/digital-to-digital":{"slug":"CN/digital-to-digital","filePath":"CN/digital to digital.md","title":"digital to digital","links":["CN/NRZ"],"tags":[],"content":"digital data ⇒ digital signal\ntypes of digital signals:\n\nunipolar:\n\nall signal levels are on one side of time axis either above or below\n\n\n\npolar:\n\nsignal levels will be on both sides of time axis\n\n\n\n\n\n\n\nPolar signal encoding techniques:\n\nNRZ (non-return to zero) (also in unipolar) NRZ\nRZ (return to zero)\nbiphase\n\nManchester\nDifferential Manchester\n\n\n"},"DBMS/DBMS":{"slug":"DBMS/DBMS","filePath":"DBMS/DBMS.md","title":"DBMS","links":["tags/Concurrency","tags/Transaction"],"tags":["Concurrency","Transaction"],"content":"\nHow to prepare DBMS from my playlist efficiently for gate 2023 | How to get full marks in DBMS\n\n\nDBMS REVISION IN 15 MIN | HOW TO REVISE SUBJECTS EFFICIENTLY?? | GATE\n\n\nDBMS Syllabus for GATE | GATE 2023\n\n\n1. DBMS introduction part 1\n\n\n2. DBMS intro part 2\n\n\n3. DBMS intro part 3\n\n\n4. ER model introduction\n\n\n5. Attributes in ER model\n\n\n6. introduction to keys\n\n\n7. types of keys\n\n\n8. relationships introduction\n\n\n9. Maximum cardinality\n\n\n10. minimum cardinality\n\n\n11. relationship between strong and weak entity type\n\n\n12. existance dependencies\n\n\n13. Generalization and specialization\n\n\n14. 3 questions on genralization and specialization\n\n\n15. constraints on generalization and specialization\n\n\n16. Aggregation\n\n\n17. Relational model introduction\n\n\n18. concept of keys in relational model\n\n\n19. Integrity constraints in relational model\n\n\n20. converting ER model to tables(Entity type and attributes)\n\n\n21. transforming binary relationships (one to many or many to one)to tables\n\n\n22. converting binary relationships (one to one) to tables\n\n\n23. transforming binary relationships (many to many)to tables\n\n\n24. summary of transforming binary relationships to tables\n\n\n25. question on conversion of binary relationships to tables\n\n\n26. question on er model to tables\n\n\n27. GATE 2004,2005,2008 QUESTION ON CONVERTING ER MODEL TO TABLES\n\n\n28. GATE 2015 AND 2018 QUESTION ON CONVERTING ER MODEL TO TABLES\n\n\n29. transforming unary relationships into tables\n\n\n30. converting generalization or specialization into tables\n\n\n31. converting aggregation into tables\n\n\n32. relational algebra intro\n\n\n33. selection operator in relational algebra\n\n\n34. projection operator in relational algebra\n\n\n35. union operator in relational algebra\n\n\n36. set difference operator in relational algebra\n\n\n37. cartesian product operator in relational algebra\n\n\n38. queries using cartesian product\n\n\n39. query explaining renaming operator\n\n\n40. more queries explaining renaming operator\n\n\n41. optimizing queries using renaming operator\n\n\n42. how to find largest and smallest in relational algebra\n\n\n43. important queries on cartesian product\n\n\n44. how to find greater than least and lesser than greatest\n\n\n45. intersection operator in relational algebra\n\n\n46. types of joins in relational algebra\n\n\n47. natural join in relational algebra\n\n\n48. queries on natural join\n\n\n49. Semi and anti join in relational algebra\n\n\n49.1 outer join in relational algebra\n\n\n50. Division operator in relational algebra\n\n\n51. queries on division operator\n\n\n52. null in relational algebra\n\n\n53. modification of database in relational algebra\n\n\n54. gate 1998 question on relational algebra\n\n\n55. gate 1999 question on relational algebra\n\n\n57. gate 2004 question on relational algebra\n\n\n56. gate 2007 question on relational algebra\n\n\n58. gate 2004 question 2 on relational algebra\n\n\n59. gate 2007 question 2 on relational algebra\n\n\n60. gate 2007 question on relational algebra\n\n\n62. gate 2008 question on relational algebra\n\n\n61. gate 2014 question on relational algebra\n\n\n63. gate 2012 question on relational algebra\n\n\n64. gate 2017 question on relational algebra\n\n\n65. minimum and maximum tuples in natural join\n\n\n66. gate 2018 question on relational algebra\n\n\n67. Introduction to tuple calculus\n\n\n68. join in tuple calculus\n\n\n69. Gate 2007 question on tuple calculus\n\n\n70. Gate 2001 question on tuple calculus\n\n\n71. Difference between for all and their exists quantifier\n\n\n72. Gate 2009 question on tuple calculus\n\n\n73. intro to domain relational calculus\n\n\n74. Gate 2013 question on domain calculus\n\n\n75. Introduction to SQL\n\n\n76. INTRO TO SET OPERATORS UNION INTERSECTION AND MINUS\n\n\n77. IN SOME ALL set operation in SQL\n\n\n78. finding greatest and least using ALL operator\n\n\n79. Few queries on IN operator\n\n\n80. CONTAINS set operation in SQL\n\n\n81. EXISTS AND NOT EXISTS set operation in SQL\n\n\n82. unique set operation in SQL\n\n\n83. Gate 2003 question on SQL\n\n\n84. Gate 2006 question on SQL\n\n\n85. gate 2007 question on SQL\n\n\n86. gate 2011 question on SQL\n\n\n87. Gate 2012 question on SQL\n\n\n88. Gate 2014 question on SQL\n\n\n89. SORTING TUPLES IN OUTPUT OF SQL QUERY\n\n\n90. aggregate functions in SQL\n\n\n91. GROUP BY clause in SQL\n\n\n92. important points about GROUP BY  clause\n\n\n93. important query on GROUP BY clause\n\n\n93.1. GATE 2015 QUESTION ON SQL\n\n\n94.  HAVING clause in SQL\n\n\n94.1. having clause part 2\n\n\n95. having and where clause difference\n\n\n96. GATE 2005 QUESTION ON SQL\n\n\n97. HANDLING NULL IN SQL\n\n\n98. pattern matching in sql\n\n\n99. handling duplicate values in SQL\n\n\n100. handling empty subquery in SQL\n\n\n101. complex query in SQL\n\n\n102. GATE 2016 question on SQL\n\n\n103. JOINS in sql\n\n\n104. modification of database\n\n\n104.1. GATE 2004 QUESTION ON SQL\n\n\n105. views in sql\n\n\n106. truncate and drop command in sql\n\n\n107. create command in sql\n\n\n107.1 GATE 1999 QUESTION ON SQL\n\n\n108. on delete cascade\n\n\n108.1 GATE 2005 and 2017 QUESTION ON SQL\n\n\n109. alter command in sql\n\n\n110. grant and revoke\n\n\n111. intro to normalization\n\n\n112. functional dependency\n\n\n113. TYPES OF FD\n\n\n113.1. gate 2000 and 2002 questions on FD\n\n\n114. ARMSTRONG AXIOMS\n\n\n115. CLOSURE\n\n\n115.1 gate 2005 question on closure\n\n\n116. TYPES OF KEYS\n\n\n118. NUMBER OF SUPER KEYS\n\n\n119. PRIME VS NON PRIME\n\n\n120. HOW TO FIND HIGHEST NORMAL FORM\n\n\n121. first normal form\n\n\n122. second normal form\n\n\n123. HOW TO DECOMPOSE TILL 2 NF\n\n\n124. third normal form\n\n\n125. gate questions on normal forms\n\n\n126. why third normal form is adequate\n\n\n127. how to check decomposition is lossy or lossless\n\n\n128. how to check FDs are preserved in decomposition\n\n\n129. gate 2008 and 2019 questions on good decomposition\n\n\n130. Is 3 NF perfect\n\n\n131. BCNF\n\n\n132. IMPORTANT POINTS ABOUT NORMAL FORMS\n\n\n133. COVER\n\n\n134. gate 2017 question on cover\n\n\n135. WHY BCNF IS NOT PERFECT NORMAL FORM\n\n\n136. 4th normal form\n\n\n137. gate 2007 question on MVD\n\n\n138. 5th normal form\n\n\n139. introduction to transactions\n\n\n140. concept of read and write item\n\n\n141. few terms in transactions\n\n\n142. acid properties\n\n\n143. why concurrency control is needed\n\n\n144. schedule\n\n\n145. Types of schedules and intro to serial schedule\n\n\n146. serializable schedule\n\n\n146.1 gate 1999,2004,2005 question on serializablity\n\n\n146.2 gate 2012 question on serializablity\n\n\n147. conflict equivalent schedule\n\n\n147.1 gate 2008 question on conflict equivalent schedules\n\n\n148. conflict serializability\n\n\n148.1 number of conflict serializable schedules (GATE 2017)\n\n\n149. how to check conflict serializability\n\n\n150. why concurrency control techniques are based on conflict serilaizability\n\n\n151. why concept of view serializability\n\n\n152. view equivalent schedules\n\n\n153. view serializability\n\n\n154. how to check view serializability\n\n\n155. recoverable schedule\n\n\n155.1 gate 2016 question on recoverability\n\n\n155.2 gate 2014 question on conflict serializablity and recoverability\n\n\n156. cascadeless schedule\n\n\n157. strict schedule\n\n\n158. relationship between schedules\n\n\n159. Introduction to lock based techniques| Concurrency Control Technique in Transaction\n\n\n160. 2 phase locking (2pl)\n\n\n161. Drawbacks in 2 Phase Locking(2PL) Protocol with examples | Concurrency Control | DBMS\n\n\n162. Basic 2PL ,Conservative 2PL ,Strict 2PL and  Rigorous 2PL in DBMS | 2 Phase Locking in DBMS\n\n\n162.1 gate 2007 question on strict 2PL\n\n\n163. timestamp ordering protocol introduction\n\n\n164. basic timestamp ordering protocol\n\n\n165. THOMAS WRITE RULE\n\n\n166. relationship between timestamp ordering and 2pl\n\n\n167. total, strict, multi version timestamp ordering protocol\n\n\n168. deadlock handling in transactions\n\n\n168.1 gate 2017 question on deadlocks\n\n\n168.2 gate 2016 question on deadlocks\n\n\n169. optimistic concurrency control technique\n\n\n170. log based recovery\n\n\n170.1  gate 2006 question on recovery\n\n\n171. checkpoints in log based recovery\n\n\n171.1 gate 2015 question on checkpoints\n\n\n172. introduction and few numerical on hard disk\n\n\n173. spanned vs unspanned strategy\n\n\n174. pile or heap file organization\n\n\n175. sequential file organization\n\n\n176. indexed sequential file organization\n\n\n177. types of indexes\n\n\n178. primary indexing\n\n\n179. numerical on primary indexing\n\n\n180. clustered indexing\n\n\n181. numerical on clustered indexing\n\n\n182. secondary indexing\n\n\n183. numerical on secondary indexing\n\n\n184. summary of indexing\n\n\n185. gate 2008 question on indexing\n\n\n186. multi level indexing\n\n\n187. why dynamic multi level indexing\n\n\n188. B-tree introduction\n\n\n189. numerical on B tree\n\n\n190. b tree insertion\n\n\n191. deletion in b tree\n\n\n192. b+ tree\n\n\n193. numerical on B+ tree\n\n\n194. b+ tree insertion\n\n\n195. b+ tree deletion\n\n\n196. gate 2005 question on b+ tree\n\n\n197. gate questions on order of B+ tree\n\n\n198. gate 2009 question on B+ tree\n\n\n199. gate 2010 question on B+ tree\n\n\n200. gate 2015 question on b+ tree\n\n\n201. gate 2007 question on B+ tree\n\n\n202. GATE 2020 b+ TREE question\n\n\n203. gate 2005 question on nested loop join\n\n\nDBMS completed\n"},"DM/discrete-maths":{"slug":"DM/discrete-maths","filePath":"DM/discrete maths.md","title":"discrete maths","links":["tags/GATE","tags/discretemaths","tags/discrete","tags/grouptheory"],"tags":["GATE","discretemaths","discrete","grouptheory"],"content":"\nHow to prepare Discrete maths from my playlist efficiently for gate 2023 |  Full marks in Discrete\n\n\n1. Discrete Mathematics introduction\n\n\n2. Introduction to logic\n\n\n3. propositions\n\n\n4. logical operators or connectives\n\n\n5. properties of basic operators | laws of boolean algebra | laws in sets\n\n\n6. practice questions on minimization\n\n\n7. GATE questions on Minimization\n\n\n8. Derived operators and properties\n\n\n9. practice question on minimization(derived operators)\n\n\n10. gate 1990 question on well formed formula (wff)\n\n\n11. GATE 1992 question on minimization\n\n\n12. GATE 1993 AND 1994 QUESTION ON LOGIC\n\n\n13. GATE 1996 question on logic\n\n\n14. GATE 2000 AND 2001 QUESTION ON LOGIC\n\n\n15. GATE 2004 AND 2005 QUESTION ON LOGIC\n\n\n16. GATE 2006 QUESTIONS ON LOGIC\n\n\n17. GATE 2008 AND 2009 QUESTION ON LOGIC\n\n\n18. GATE 2014 AND 2015 QUESTIONS ON LOGIC\n\n\n19. GATE 2016 AND 2017 QUESTION ON LOGIC\n\n\n20. tautology,contradiction and contingency\n\n\n21. Normal Forms\n\n\n22. GATE 2014 QUESTION ON NORMAL FORMS\n\n\n23. properties of normal forms\n\n\n24. IMPLICATION\n\n\n25. Gate 2001 and 2002 question on logic\n\n\n26. GATE 2014, 2016 AND 2017 QUESTION ON LOGIC\n\n\n27. BICONDITIONAL\n\n\n28. keywords for translations\n\n\n29. practice questions on implication\n\n\n31. introduction to arguments\n\n\n30. gate 2015 question on logic\n\n\n32. Rules of inference\n\n\n33. practice questions on arguments\n\n\n34. GATE 2004,2012,2015 question on logic\n\n\n35. predicates and quantifiers in predicate logic\n\n\n36. concept of scope of variables and free variables\n\n\n37. nested quantifiers\n\n\n38. practice questions on nested quantifiers\n\n\n39. negating quantifiers\n\n\n40. properties of quantifiers\n\n\n41. gate 1992 question on logic\n\n\n42. gate 2003 question on logic\n\n\n43. gate 2004 and 2008 question on logic\n\n\n44. gate 2005 question on logic\n\n\n45. gate 2007 question on logic\n\n\n46. gate 2008 question on logic\n\n\n47. gate 2015 question on logic\n\n\n48. gate 2016 and 2017 question on logic\n\n\n49. basics of translations in predicate logic\n\n\n50. practice questions on translations(part 1)\n\n\n51. practice questions on translations(part 2)\n\n\n52. practice questions on translations(part 3)\n\n\n53. practice questions on translations(part 4)\n\n\n54. translating at least, at most and exactly\n\n\n55. GATE 2003 QUESTION ON LOGIC\n\n\n56. GATE 2004,2005 and 2006 QUESTION ON LOGIC\n\n\n57. GATE 2006,2007 and 2008 QUESTION ON LOGIC\n\n\n58. GATE 2009 and 2010 QUESTION ON LOGIC\n\n\n59. GATE 2011,2012 and 2013 QUESTION ON LOGIC\n\n\n60. GATE 2013,2014 and 2019 QUESTION ON LOGIC\n\n\n61. rules of inference in predicate logic\n\n\n62. arguments in predicate logic\n\n\nGATE 2018 Question On Logic Part 1\n\n\nGATE 2018 Question On Logic Part 2\n\n\nGATE 2018 Question On Logic Part 3\n\n\nGATE 2018 Question On Logic Part 4\n\n\nlogic is completed\n\n\n63. SYLLABUS OF COMBINATORICS\n\n\n64. FUNDAMENTAL PRINCIPLE OF COUNTING |  The Fundamental Counting Rule Principle\n\n\n65. 9 CATEGORIES OF PROBLEMS IN P AND C\n\n\n66. practice questions on permutations part 1\n\n\n67. practice questions on permutations part 2\n\n\n68. practice questions on permutations part 3\n\n\n69. 6 categories of constraints in permutations(part 1)\n\n\n70. 6 categories of constraints in permutations (part 2)\n\n\n71. 6 categories of constraints in permutations part 3\n\n\n72. combinations with no repetition\n\n\n73. combinations with unlimited repetition (part 1)\n\n\n74. combinations with unlimited repetition part 2\n\n\n75. combinations with limited repetition using generating functions\n\n\n76. Distribution problems (category 7)\n\n\n77. principle of inclusion exclusion(category 8)\n\n\n78. DERANGEMENT\n\n\n79. pigeon hole principle(category 9)\n\n\n80. practice questions pigeon hole principle\n\n\n81. INTRODUCTION TO BINOMIAL AND MULTINOMIAL SUMMATIONS\n\n\n82. properties of binomial coefficient(part 1)\n\n\n83. properties of binomial coefficient part 2\n\n\n84. properties of binomial coefficient part 3\n\n\n85. generating functions part 1\n\n\n86. generating functions part 2\n\n\n87. generating functions part 3\n\n\n88. generating functions part 4\n\n\n89. introduction to recurrence relations\n\n\n90. solving recurrence relations (part 1)\n\n\n91. solving recurrence relations(part 2)\n\n\n92. solving recurrence relations(part 3)\n\n\n93. miscellaneous topics in combinatorics\n\n\n94. gate 1987 question on recurrence relations\n\n\n95. gate 1987 question on generating function\n\n\n96. gate 1988 question on recurrence relations\n\n\n97. gate 1990 question on P AND C\n\n\n98. gate 1998 question on principle of inclusion exclusion\n\n\n99. gate 1998 question on recurrence relation\n\n\n100. gate 1999 question on P AND C\n\n\n101. gate 2000 question on PIGEON HOLE PRINCIPLE\n\n\n102. gate 2001 question on  P AND C\n\n\n103. gate 2002 question on recurrence relations\n\n\n104. gate 2003 question on  P AND C\n\n\n105. gate 2003 question on  P AND C\n\n\n106. GATE 2004 QUESTION ON P AND C\n\n\n107. GATE 2004 QUESTION ON DERANGEMENT\n\n\n108. GATE 2005 QUESTION ON EULER TOTIENT FUNCTION\n\n\n109. GATE 2005 QUESTION ON PIGEON HOLE PRINCIPLE\n\n\n110. GATE2005 QUESTION ON GENERATING FUNCTION\n\n\n111. GATE 2006 QUESTION OF PROBABILITY\n\n\n112. grid problem gate 2007 question\n\n\n113. GATE 2008 QUESTION ON SUMMATION\n\n\n114. GATE 2008 QUESTION ON RECURRENCE RELATION\n\n\n115. gate 2008 question on factorial\n\n\n116. GATE 2008 QUESTION ON P AND C\n\n\n117. GATE 2014 PENNANT QUESTION\n\n\n118. GATE 2014 QUESTION ON NUMBER OF DIVISORS\n\n\n119. GATE 2015 COMBINATORICS QUESTION\n\n\n120. GATE 2015 QUESTION ON NUMBER OF DIVISORS\n\n\n121. GATE 2015 QUESTION ON RECURRENCE RELATION\n\n\n122. GATE 2015 QUESTION ON SUMMATION\n\n\n123. GATE 2016 QUESTION ON  GENERATING FUNCTION\n\n\n124. GATE 2016 QUESTION ON RECURRENCE RELATION\n\n\n125. GATE 2016 RECURRENCE RELATION QUESTION\n\n\n126. GATE 2017 QUESTION ON GENERATING FUNCTION\n\n\n127. GATE 2018 QUESTION ON GENERATING FUNCTION\n\n\nGATE 2022 GENERATING FUNCTION QUESTION EASIEST EXPLANATION\n\n\n128. Gate 2019 question on combinatorics\n\n\n129. gate 2020 question on derangement\n\n\n130. combinatorics completed\n\n\n131. syllabus of set theory\n\n\n132. INTRODUCTION TO SET THEORY\n\n\n133. SYLLABUS OF RELATIONS CHAPTER\n\n\n134. introduction to relations (PART 1)\n\n\n135. introduction to relations (part 2)\n\n\n136. R-relative sets\n\n\n137. operations on relations part 1\n\n\n138. operations on relations part 2\n\n\n139. 8 WAYS TO REPRESENT RELATIONS\n\n\n140. types of relations part 1 reflexive relations\n\n\n141. types of relations part 2 (irreflexive relations)\n\n\n142. types of relations part 3 symmetric relations\n\n\n143. types of relations part 4 antisymmetric relations\n\n\n144. types of relations part 5 asymmetric relations\n\n\n145. types of relations part 6 transitive relations\n\n\n146. practice questions on types of relations\n\n\n147. counting relations and closure properties of relations\n\n\n148. mix questions on counting relations\n\n\n149. closure of finite relations\n\n\n150. closure of infinite relations\n\n\n151. introduction to equivalence relations\n\n\n152. equivalence class , quotient set and partition\n\n\n153. EQUIVALENCE CLASS | QUOTIENT SET | PARTITION | NUMBER OF EQUIVALENCE RELATIONS\n\n\n154. theorems in relations chapter\n\n\n155. interpretation of powers of relations\n\n\n156. relations chapter completed!!\n\n\n157. syllabus of functions chapter\n\n\n158. introduction to functions\n\n\n159. types of functions part 1\n\n\n160. types of functions part 2\n\n\n161. types of functions part 3\n\n\n162. practice questions on types of functions\n\n\n163. counting functions part 1\n\n\n164. counting functions part 2\n\n\n165. practice question on counting functions\n\n\n166. practice question on counting functions part 2\n\n\n167. composition of functions(part 1)\n\n\n168. composition of functions (part 2)\n\n\n169. inverse functions\n\n\n170. permutation function\n\n\n171. set theory completed!\n\n\n172. GATE 1987 QUESTION ON SET THEORY\n\n\n173. GATE 1989,1993 QUESTION O SET THEORY\n\n\n174. GATE 1995 QUESTION ON SET THEORY\n\n\n175. GATE 1996 QUESTION ON SET THEORY\n\n\n176. GATE 1997 QUESTION ON number of equivalence relations\n\n\n177. GATE 1998 QUESTION ON SET THEORY\n\n\n178. GATE 1999 QUESTION ON SET THEORY\n\n\n179. GATE 2000 QUESTION O SET THEORY\n\n\n180. GATE 2001 QUESTION O SET THEORY\n\n\n181. GATE 2002 QUESTION ON SET THEORY\n\n\n182. GATE 2004 QUESTION ON SET THEORY\n\n\n183. GATE 2005 QUESTION ON SET THEORY\n\n\n184. GATE 2006 QUESTION ON SET THEORY\n\n\n185. gate 2007,2009,2010 questions on set theory\n\n\n186. GATE 2012 and 2014 QUESTION ON SET THEORY\n\n\n187. GATE 2014 and 2015 QUESTION ON SET THEORY\n\n\n188. GATE 2016 and 2017 QUESTION ON SET THEORY\n\n\nHUMBLE REQUEST BEFORE STARTING GROUP THEORY\n\n\n189. syllabus of group theory\n\n\n190. binary operation\n\n\n191. classification of algebraic structure GATE discretemaths discrete grouptheory\n\n\n192. practice questions on classification of algebraic structure\n\n\n193. practice questions on classification of algebraic structure(part 2)\n\n\n194. practice questions on classification of algebraic structure (part 3)\n\n\n195. abelian groups\n\n\n196. standard examples of groups part 1\n\n\n197. standard examples of groups part 2\n\n\n198. properties of group part 1\n\n\n199. properties of group part 2\n\n\n200. powers of element of group\n\n\n201. order of element of group\n\n\n202. properties of order of element of group\n\n\n203. CYCLIC GROUPS\n\n\n204. properties of cyclic group part 1\n\n\n205. properties of cyclic group part 2\n\n\n206. properties of cyclic group part 3\n\n\n207. properties of cyclic group part 4 | Euler function\n\n\n208. subgroups part 1\n\n\n209. subgroups part 2\n\n\n210. subgroups part 3\n\n\n211. subgroups part 4\n\n\n212. group theory completed!!!  What next???\n\n\n213. gate 1994 question on group theory\n\n\n214. gate 1995 question on group theory\n\n\n215. gate 1996 question on group theory\n\n\n216. gate 1998 question on group theory\n\n\n217. gate 2003 question on group theory\n\n\n218. gate 2004 question on group theory\n\n\n219. gate 2005 question on group theory\n\n\n220. gate 2006question on group theory\n\n\n221. gate 2009 question on group theory\n\n\n222. gate 2010 and 2013 question on group theory\n\n\n223. gate 2014 questions on group theory\n\n\n224. gate 2015 and 2018 question on group theory\n\n\n225. gate 2019 question on group theory\n\n\n226. syllabus of poset, lattice and boolean algebra\n\n\n227. introduction to posets\n\n\n228. Hasse diagram part 1\n\n\n229. hasse diagram part 2\n\n\n230. toset and woset\n\n\n231. topological sorting part 1\n\n\n232. topological sorting part 2\n\n\n233. maximal and minimal elements of posets\n\n\n234. greatest and least element of poset\n\n\n235. upper bound, least upper bound ,lower bound, greatest lower bound of any subset of poset\n\n\n236. shortcut to find extremal elements of posets\n\n\n237. semi lattice and lattice part 1\n\n\n238. semi lattice and lattice part 2\n\n\n239. semi lattice and lattice part 3\n\n\n240. properties of lattice part 1\n\n\n241. properties of lattice part 2\n\n\n242. Sublattice\n\n\n243. BOUNDED LATTICE\n\n\n244. complimented lattice\n\n\n245. complimented lattice part 2\n\n\n246. distributive lattice\n\n\n247. complete lattice\n\n\n248. boolean algebra\n\n\nsyllabus of discrete probability\n\n\nbasic terms used in probability\n\n\nconditional probability practice questions\n\n\nconditional probability practice questions 2\n\n\nmultiplication theorem part 1\n\n\nmultiplication theorem practice questions\n\n\nIndependent Events PART 1\n\n\nIndependent Events PART 2\n\n\nIndependent Events part 3\n\n\nIndependent Events part 4\n\n\nTotal probability and Baye’s theorem part1\n\n\nTotal probability and bayes theorem part2\n\n\nTotal probability and bayes theorem part3\n\n\nTotal probability and bayes theorem part4\n\n\nsyllabus of graph theory\n\n\nintroduction to graph theory\n\n\ndegree of vertex\n\n\nHandshaking theorem part 1\n\n\nHandshaking theorem part 2\n\n\ndelta delta theorem\n\n\nhavel hakimi theorem\n\n\nspecial graphs part 2\n\n\nspecial graphs part 1\n\n\nchromatic number of special graphs\n\n\ndiameter of special graphs\n\n\nrepresentation of graphs\n\n\nOperations on Graphs in Graph Theory | Intersection of graphs | union of graphs\n\n\nOperations on Graphs in Graph Theory | compliment of graphs\n\n\nOperations on Graphs in Graph Theory | set difference of graphs |  ring sum of graphs\n\n\nIsomorphism in Graph Theory in Hindi\n\n\nWOSET Definition\n\n\nSubgraph | Induced subgraph | clique\n\n\nconnected components | connected and disconnected graphs\n\n\ncut vertex | cut edge | cut set | articulation points | bridge\n\n\nVertex connectivity | Edge connectivity\n\n\nconnectivity of graph\n\n\nStrongly Connected Directed Graphs | Unilaterally connected Digraphs | weakly connected Digraphs\n\n\nDifference between Walk, Trail, Path, Circuit and Cycle with most suitable example | Graph Theory\n\n\nPlanar Graph and Detection of Planarity in Graph Theory | Part 1\n\n\nPlanar Graph and Detection of Planarity in Graph Theory | Part 2\n\n\nPlanar Graph and Detection of Planarity in Graph Theory | Part 3\n\n\nPlanar Graph and Detection of Planarity in Graph Theory | Part 4\n\n\nTrees in graph theory | part 1 | GATE 2023\n\n\nTrees in graph theory | part 2 | GATE 2023\n\n\nTrees in graph theory | part 3 | Spanning trees | GATE 2023\n\n\nTrees in graph theory | part 4 | Counting spanning trees | GATE 2023\n\n\nTrees in graph theory | part 5 | rank and nullity of graph | branch set and chord set | GATE 2023\n\n\nTrees in graph theory | part 6 | eccentricity | center | radius | diameter of graph | GATE 2023\n\n\nCounting labeled graphs | Counting unlabeled graphs | Number of simple graph with n vertices\n\n\nGraph numbers | chromatic number of graphs | GATE 2023\n\n\nGraph numbers | chromatic number of graphs | GATE 2023 | part 2\n\n\nGraph numbers | Independence number of graphs | GATE 2023\n\n\nGraph numbers | Domination number of graphs | GATE 2023\n\n\nGraph numbers | Matching number of graphs | GATE 2023\n\n\nGraph numbers | Covering number of graphs | GATE 2023\n\n\nPerfect Matching in Graph Theory | Properties of Perfect Matching | Discrete Mathematics GATE\n\n\nHow to Revise  Discrete Mathematics | GATE 2023 Computer Science Engineering (CSE) Exam Preparation\n\n\nconditional probability\n\n\nEuler Graph in Graph Theory\n\n\nUnicursal Graph in Graph Theory\n\n\nHamiltonian Graph with examples | Hamiltonian Path &amp; Circuit | Part 2\n\n\nHamiltonian Graph with examples | Hamiltonian Path &amp; Circuit | Part 1\n\nGATE 2023 Solution\nGenerating Functions (from Discrete Maths)\nC Language for GATE — Complete Playlist\nDigital Logic for GATE — Complete Playlist\nNIR BHAU series Compiler Design\nLogic (from Discrete Maths)\nData Structures and Algorithms for GATE — Complete Playlist\nNIR BHAU Series OS\nDiscrete Mathematics | CS &amp; IT | GATE 2024 Series\nThe GATE Toppers Podcast"},"DM/long/Graph_Theory_Adjacency_Matrix":{"slug":"DM/long/Graph_Theory_Adjacency_Matrix","filePath":"DM/long/Graph_Theory_Adjacency_Matrix.md","title":"Graph_Theory_Adjacency_Matrix","links":["tags/gate","tags/dm","tags/long","tags/graphs"],"tags":["gate","dm","long","graphs"],"content":"gate dm long graphs\nAdjacency Matrix\nDefinition\nAn Adjacency Matrix represents a graph with n vertices as an n×n matrix A, where each cell Aij​ indicates whether there is an edge between vertex i and vertex j.\nFor a simple graph with vertex set V={v1​,v2​,…,vn​}:\nAij​={10​if (vi​,vj​)∈Eotherwise​\nExample and Diagram\nConsider a graph with 4 vertices (1,2,3,4) forming a cycle with a chord.\nGraph Diagram:\ngraph TD\n    1((1)) --- 2((2))\n    2((2)) --- 3((3))\n    3((3)) --- 4((4))\n    4((4)) --- 1((1))\n    2 --- 4\n\nAdjacency Matrix:\nA=​0101​1011​0101​1110​​\n\nProperties\n\nThe entries along the principal diagonal of X are all 0’s if and only if the graph has no self-loops. A self-loop at the i-th vertex corresponds to Aii​=1.\nThe definition of adjacency matrix makes no provision for parallel edges (this matrix representation is typically for simple graphs).\nIf the graph has no self-loops, then the degree of the vertex is the number of 1s in the column or row for that vertex.\n\ndeg(vi​)=∑j=1n​Aij​\n\n\n\n\nNote: The Adjacency Matrix ordinally depends on how we label the vertices. Relabeling vertices results in a permutation of rows and columns (permutation similarity).\n\n\nPowers of Adjacency Matrix &amp; Walks\nOne interesting property of the adjacency matrix concerns its various powers.\nThe length of a walk is the number of occurrences of edges in it.\nLet Ak be the k-th power of the adjacency matrix A.\nThe entry (Ak)ij​ equals the number of walks of length k from vertex i to vertex j.\nExample\nLet:\nA=​0100​1011​0101​0110​​\nThen A2:\nA2=​1011​0311​1121​1112​​\nAnd A3:\nA3=​0311​3244​1423​1432​​\nInterpretation:\n\n\n(A2)ij​=x means there are x different walks from i→j of length 2.\n\n\nPrincipal Diagonal of A2:\n\nA walk of length 2 starting and ending at the same vertex i (i→k→i) involves going to a neighbor and coming back.\nThus, (A2)ii​=deg(vi​).\nTrace of A2 = 2×∣E∣.\n\n\n\nPrincipal Diagonal of A3 and Triangles:\n\nA walk of length 3 starting and ending at i (i→j→k→i) corresponds to a triangle involving i (if i,j,k are distinct) or traversing an edge and back (which isn’t a simple cycle).\nFor simple graphs, (A3)ii​ relates to triangles.\nSpecifically, ∑(A3)ii​=Trace(A3)=6×(Number of Triangles).\nWhy division by 6?\n\nEach triangle (i,j,k) is counted for each vertex (i,j,k) → 3×.\nThe cycle can be traversed in 2 directions (i→j→k→i and i→k→j→i) → 2×.\nTotal counts per triangle = 3×2=6.\n\n\n\n\n\n\nEigenvalues — Intuition (Funzies)\nbit of a tangent, i dont know shit about eigen vectors and values so i had to chatgpt and i was trying to make it explain to me like im 5 years old lmao\n1. THE ARROW &amp; MACHINE IDEA (INTUITION)\nThink of a matrix as a machine.\nAn arrow means a direction (with some length).\nWhen you put an arrow into the machine:\n\nMost arrows come out turned (direction changes)\nSome special arrows come out in the SAME direction,\nonly stretched, shrunk, flipped, or crushed\n\nThose special arrows are called:\n→ Eigenvectors\nHow much those arrows stretch or shrink is called:\n→ Eigenvalues\nIMPORTANT:\nEigenvalues do NOT belong to one arrow.\nThey belong to the machine, discovered by testing different directions.\n\n2. A SIMPLE MATRIX (THE MACHINE)\nConsider the matrix:\nA = [ 2  2\n1  1 ]\nThis matrix is the machine.\nWhat it does to an arrow (x, y):\n\nNew x = 2x + 2y\nNew y = x + y\n\n\n3. TRY DIFFERENT ARROWS (ONE AT A TIME)\nArrow 1: (1, 0)  → right direction\nA(1, 0) = (2, 1)\nDirection changed ❌\nNot an eigenvector\nArrow 2: (0, 1)  → up direction\nA(0, 1) = (2, 1)\nDirection changed ❌\nNot an eigenvector\nArrow 3: (1, 1)  → diagonal\nA(1, 1) = (4, 2)\n(4, 2) is the SAME direction as (1, 1),\njust stretched.\nSo:\n\nEigenvector direction = (1, 1)\nEigenvalue = 2 (stretch factor)\n\nArrow 4: (1, -1)\nA(1, -1) = (0, 0)\nArrow gets completely crushed.\nDirection is preserved (just zeroed).\nSo:\n\nEigenvector direction = (1, -1)\nEigenvalue = 0\n\n\n4. FINAL RESULT FOR THIS MATRIX\nEigenvalues:\n\n2  → stretches the (1, 1) direction\n0  → crushes the (1, -1) direction\n\n\n5. KEY TAKEAWAYS (VERY IMPORTANT)\n\nA matrix can have multiple eigenvalues\nEach eigenvalue corresponds to a special direction\nEigenvectors are directions that do NOT turn\nEigenvalues tell how much those directions stretch or shrink\n\nONE-LINE SUMMARY:\nEigenvalues are the special stretch/shrink factors of a matrix along its special directions.\n\nSpectral Properties of Graphs\nLet A be the adjacency matrix of a simple graph X=(V,E). Let λ1​,λ2​,…,λn​ be the eigenvalues of A.\n\n∑λi​=0 (if more than 0 then self loop)\n∑λi2​=2×∣E(X)∣, where ∣E(X)∣ is the number of edges\n∑λi3​=6×T(X), where T(X) is the number of triangles in the graph.\n\n\nAdjacency Matrix and Connectivity\nLet X be a connected graph on n vertices. If A is its adjacency matrix then every entry of (I+A)n−1 is positive.\nExplanation (Generating Functions Analogy)\nYou can think about this using the idea of generating functions like 1−x1​=1+x+x2+x3….\nSimilarly for matrices, we can relate (I−A)−1 to the sum I+A+A2+….\nFor the specific case of (I+A)n−1, we can expand it using the Binomial Theorem:\n(I+A)n−1=I+(n−1)A+(2n−1​)A2+⋯+An−1\nSince all coefficients are positive, the result is a weighted sum of powers of adjacency matrices.\n\nAk has non-zero entries where there is a walk of length k.\nIf a graph is connected, between any two vertices there is a path of length at most n−1.\nTherefore, the sum will definitely have a non-zero contribution from one of the Ak terms for every pair of vertices.\nSince we are adding Identity I, the diagonal is covered.\nSince we are adding A,A2…, all connected paths are covered.\nThus, every entry in the resulting matrix is positive.\n\n\nRelevant PYQs\nGATE IT 2005 | Question: 84b\nDiscussion Link\nIf there is at least a 1 in each of A’s rows and columns, then:\n\nthe graph must be connected.\nThe diagonal entries of A2 are the degrees of the vertices of the graph.\nIf the graph is connected, then none of the entries of An−1+In​ can be zero.\n(Check original question for full context)\n\nGATE CSE 2022 | Question: 42\nDiscussion Link\nThis question involves adjacency matrix properties related to connected components and eigenvalues."},"DM/long/Graph_Theory_Basics":{"slug":"DM/long/Graph_Theory_Basics","filePath":"DM/long/Graph_Theory_Basics.md","title":"Graph_Theory_Basics","links":["tags/gate","tags/dm","tags/long","tags/graphs"],"tags":["gate","dm","long","graphs"],"content":"gate dm long graphs\nGraph Theory Basics\n1. Introduction\nGraph Theory is the study of graphs, which are mathematical structures used to model pairwise relations between objects.\nDefinitions:\n\nVertex (Point/Join): Represents an object or node. Denoted by V.\nEdge (Line/Branch): Represents a connection between two vertices. Denoted by E.\nGraph (G): A graph is defined as an ordered pair G=(V,E), where V is a set of vertices and E is a set of edges.\n\nEach edge is associated with an unordered pair of vertices {u,v}.\n\n\n\n\n2. Degree of a Vertex\nThe degree (or valency) of a vertex v, denoted as d(v), is the number of edge ends connecting to it.\n\nUnofficial definition: Number of “welding points” at a vertex.\n\nExample:\nConsider a graph with vertices V={v1​,v2​,v3​} and edges E={e1​,e2​} where v2​ is connected to v1​ and v3​.\n\nd(v1​)=1\nd(v2​)=2\nd(v3​)=1\n\nSum of degrees: 1+2+1=4.\nNumber of edges (∣E∣) = 2.\nNotice that 4=2×2.\nHandshaking Lemma (First Theorem of Graph Theory)\nThe sum of degrees of all vertices in a graph is equal to twice the number of edges.\n∑i=1n​d(vi​)=2∣E∣\nConsequence: The sum of degrees is always even.\nTheorem 2: Odd Degree Vertices\nSince ∑d(vi​) is always even:\n∑dodd​+∑deven​=Even\nSince the sum of even degrees is obviously even, the sum of odd degrees must also be even. This is only possible if the number of odd-degree vertices is even.\n\n3. Simple Graph\nA Simple Graph is a graph that has:\n\nNo self-loops (an edge connecting a vertex to itself).\nNo parallel/multiple edges (multiple edges between the same pair of vertices).\n\nProperties of Simple Graphs\n1. Maximum Degree:\nIn a simple graph with n vertices, a vertex can be connected to at most all other n−1 vertices.\nΔ(G)≤n−1\n2. Maximum Number of Edges:\nSince the maximum degree is n−1, if we sum the max degrees: ∑d(vi​)=n(n−1).\nUsing the Handshaking Lemma 2∣E∣=∑d(vi​):\n2∣E∣max​=n(n−1)\n∣E∣max​=2n(n−1)​\nThis is equivalent to choosing 2 vertices out of n to form an edge: (2n​).\n3. Average Degree:\nAvg Degree=n∑d(vi​)​=n2∣E∣​\n4. Degree Inequalities (Theorem 5):\nδ(G)≤n2∣E∣​≤Δ(G)≤n−1\nWhere δ(G) is the minimum degree and Δ(G) is the maximum degree.\n\n4. Degree Sequence\nA degree sequence is the list of degrees of all vertices in the graph, usually written in non-increasing or non-decreasing order.\nGraphical Sequence: A sequence of numbers is called graphical if there exists a simple graph with that degree sequence.\nHavel-Hakimi Algorithm\nA procedure to determine if a sequence is graphical.\nSteps:\n\nSort the sequence in descending order.\nRemove the first element, say k.\nSubtract 1 from the next k elements in the sequence.\nIf negative numbers appear, it’s not graphical.\nIf we reach all zeros, it is graphical.\nSort again and repeat.\n\nExample from notes:\nSequence: 7, 6, 5, 4, 4, 3, 2, 1\n\nRemove 7. Subtract 1 from next 7 elements:\n5, 4, 3, 3, 2, 1, 0\nRemove 5. Subtract 1 from next 5 elements:\n3, 2, 2, 1, 0, 0 (and 0 at end)\nRemove 3. Subtract 1 from next 3 elements:\n1, 1, 0, 0, 0, 0\nRemove 1. Subtract 1 from next 1 element:\n0, 0, 0, 0, 0\n\nResult: All zeros → The sequence is Graphical.\n\n5. Counting Graphs\nTotal number of possible simple graphs with n vertices.\nSince the maximum number of edges is N=2n(n−1)​, and each edge has 2 possibilities (exists or doesn’t exist):\nTotal Simple Graphs=2N=22n(n−1)​\n(Note provided example: 26 likely refers to a case where max edges = 6, i.e., n=4)\n6. Special Types of Graphs\n6.1 Complete Graph (Kn​)\nA simple graph where every pair of distinct vertices is connected by a unique edge.\n\nDegree: Every vertex has degree n−1.\nNumber of Edges: Since every vertex connects to every other:\n∣E∣=(2n​)=2n(n−1)​\n\n6.2 Regular Graph\nA graph where every vertex has the same degree k. Such a graph is called k-regular.\n\nProperties:\n\nδ(G)=Δ(G)=k\nFrom Handshaking Lemma: n×k=2∣E∣⟹∣E∣=2nk​\n\n\nExamples:\n\nKn​ is (n−1)-regular.\nCycle graph Cn​ is 2-regular.\nNull graph Nn​ is 0-regular.\n\n\n\n6.3 Cycle Graph (Cn​)\nA graph with n vertices (n≥3) containing a single cycle through all vertices.\n\nStructure: Closed loop.\nRegularity: It is always 2-regular.\nEdges: Number of edges = Number of vertices = n.\n\n6.4 Wheel Graph (Wn​)\nConstructed by taking a Cycle Graph Cn−1​ and adding a new vertex (Hub) connected to all vertices of the cycle.\n\nVertices: n (where n−1 are on the rim, 1 is center). note: n≥4.\nEdges:\n\nRim edges (Cn−1​): n−1\nSpoke edges (Hub to Rim): n−1\nTotal Edges: 2(n−1)\n\n\nDegrees:\n\nDegree of Hub: n−1\nDegree of Rim vertices: 3\n\n\n\n6.5 Bipartite Graph\nA graph where the vertex set V can be partitioned into two disjoint sets V1​ and V2​ such that every edge connects a vertex in V1​ to one in V2​.\n\nNo Internal Edges: No edge connects two vertices within the same set (V1​ or V2​).\nTheorem: A graph is bipartite if and only if it contains no odd length cycles.\nComplete Bipartite Graph (Km,n​):\n\nEvery vertex in V1​ (size m) is connected to every vertex in V2​ (size n).\nTotal Vertices: m+n\nTotal Edges: m×n\n\n\n\n6.6 Hypercube Graph (Qn​)\nAlso known as an n-cube.\n\nVertices: 2n vertices, each labeled with a distinct n-bit binary string.\nEdges: Two vertices are connected if their binary strings differ by exactly one bit.\nProperties:\n\nRegularity: It is n-regular (each vertex has n neighbors).\nEdges: using Handshaking Lemma: 2∣E∣=V×degree=2n×n⟹∣E∣=n2n−1.\nBipartite: All hypercubes are bipartite graphs.\n\n\n\n6.7 Complement Graph (Gˉ)\nThe complement of a graph G has the same vertex set as G. Two vertices are adjacent in Gˉ if and only if they are not adjacent in G.\n\nUnion: G∪Gˉ=Kn​ (Complete Graph).\nEdges: ∣E(G)∣+∣E(Gˉ)∣=2n(n−1)​.\n\n6.8 Self-Complement Graph\nA graph that is isomorphic to its own complement (G≅Gˉ).\n\nEdge Count:\n∣E(G)∣=∣E(Gˉ)∣⟹2∣E∣=2n(n−1)​⟹∣E∣=4n(n−1)​\nExistence Condition: For a self-complement graph to exist, the number of vertices n must satisfy n≡0(mod4) or n≡1(mod4).\n\n6.9 Line Graph L(G)\nThe line graph L(G) of a graph G is a graph where:\n\nEach vertex of L(G) represents an edge of G.\nTwo vertices of L(G) are adjacent if their corresponding edges in G share a common endpoint (are incident).\n"},"DM/long/Graph_Theory_Connectivity":{"slug":"DM/long/Graph_Theory_Connectivity","filePath":"DM/long/Graph_Theory_Connectivity.md","title":"Graph_Theory_Connectivity","links":["tags/gate","tags/dm","tags/long","tags/graphs","tags/connectivity"],"tags":["gate","dm","long","graphs","connectivity"],"content":"gate dm long graphs connectivity\nGraph Theory - Connectivity\nDate: 29/01/2026\n1. Basics of Connectivity\nDefinitions\n\n\nWalk:\n\nAn alternating sequence of vertices and edges: v0​,e1​,v1​,e2​,…,vk​.\nRule: Vertices and Edges CAN be repeated.\nAnalogy: Just walking around aimlessly.\n\n\n\nTrail:\n\nA walk with NO repeated edges.\nVertices CAN be repeated.\nKey: “Trail” sounds like leaving a mark on the path (edge), so you can’t walk on it again.\n\n\n\nPath:\n\nA walk with NO repeated vertices (and consequently no repeated edges).\nException: Start and End vertices can be same (Closed Path / Cycle).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTypeRepeat Vertices?Repeat Edges?WalkYesYesTrailYesNoPathNoNo\n\n2. Connected vs Disconnected Graphs\n\nConnected Graph: A graph is connected if there is a path between every pair of distinct vertices.\nDisconnected Graph: A graph that is not connected. It consists of two or more disjoint connected subgraphs called Components.\n\nComponents\n\nA Component is a maximal connected subgraph.\nA disconnected graph G is essentially a set of components (k≥2).\n\nConnectivity &amp; Complements (Theorems)\nLet G be a graph and Gˉ (or G′) be its complement.\n\nStatement 1: If G is connected, then Gˉ is connected. → FALSE\n\nCounter-example: C4​ is connected, C4​ˉ​=2K2​ (disconnected).\n\n\nStatement 2: If G is disconnected, then Gˉ is always connected. → TRUE\n\nLogic: If u,v are in different components in G, they are not connected. Thus, in Gˉ, there MUST be an edge between them. If they are in the same component, they can reach each other via nodes in other components.\n\n\n\nMinimum Degree &amp; Connectivity\n\n\nTheorem: If δ(G)≥2n−1​, then G is connected.\n-This ensures enough edges to force overlap between neighborhoods of any two vertices.\n\n\nTheorem (Odd Degree Pair): If a graph has exactly two vertices of odd degree (a and b), then there is always a path between a and b.\n\nConsequence: They must belong to the same component. You cannot have one odd degree node in one component and one in another (Handshaking Lemma violation per component).\n\n\n\n\n3. Range of Edges\nFor a Connected Graph with n vertices:\n\nMin Edges: n−1 (Tree structure).\nMax Edges: 2n(n−1)​ (Kn​).\nn−1≤∣E∣≤(2n​)\n\nFor a Disconnected Graph with n vertices and k components:\n\nMin Edges: n−k (Forest with k trees).\nMax Edges: Occurs when one component is Kn−k+1​ and the rest are isolated vertices (K1​).\n\nMax edges = Edges in Kn−k+1​\n∣E∣max​=2(n−k)(n−k+1)​\n\n\n\nn−k≤∣E∣≤2(n−k)(n−k+1)​\nTree Definition\n\nA Tree is a connected graph with no cycles.\nIt uses the minimum number of edges (n−1) to keep n vertices connected.\nA Forest is a collection of trees (disconnected acyclic graph).\n\n\n4. Cut Sets and Connectivity\n4.1 Cut Edge (Bridge)\n\nDefinition: An edge whose removal increases the number of components (makes the graph disconnected).\nCondition: An edge e is a bridge if and only if e is not part of any cycle.\n\n4.2 Cut Vertex (Articulation Point)\n\nDefinition: A vertex whose removal (along with incident edges) increases the number of components.\nNote: If a Cut Edge exists, a Cut Vertex may or may not exist?\n\nActually, if n&gt;2, endpoints of a bridge are cut vertices (unless they are leaves).\nCorrection from notes: “if cut edge exists then cut point may not exist” → This is true for K2​ (single edge). Removing the edge disconnects it. Removing a vertex leaves a single vertex (connected trivial graph) or empty. Technically removal of vertex v from K2​ leaves K1​ (connected). So yes, K2​ has a bridge but no cut vertex.\n\n\n\n4.3 Connectivity Measures\n\nEdge Connectivity (λ(G)): Min number of edges to remove to disconnect G.\nVertex Connectivity (κ(G)): Min number of vertices to remove to disconnect G (or leave a singleton).\n\n4.4 The Great Inequality\nκ(G)≤λ(G)≤δ(G)≤n2∣E∣​≤Δ(G)≤n−1\n\nVertex Connectivity ≤ Edge Connectivity ≤ Min Degree ≤ Avg Degree ≤ Max Degree.\n\n\n5. Problem Solving: Complement of Graph Join\nQuestion: Take Cycle Graph C3​, connect it with Wheel Graph W4​, and then complement it. How many components do we get?\nInterpretation:\n\n“Connect with” usually implies a Graph Join (G1​+G2​), where every vertex of G1​ is connected to every vertex of G2​.\nLet G=C3​+W4​.\nWe need to find components of Gˉ (Complement of G).\n\nTheorem regarding Join Complements:\n\nG1​+G2​​=G1​ˉ​∪G2​ˉ​\nThe complement of a join is the disjoint union of the complements of the individual graphs.\nSo, Components(Gˉ) = Components(C3​ˉ​) + Components(W4​ˉ​).\n\nStep 1: Analyze C3​\n\nC3​ is a triangle (K3​).\nComplement of K3​ (K3​ˉ​) is 3 isolated vertices.\nComponents in C3​ˉ​ = 3.\n\nStep 2: Analyze W4​\n\nW4​ usually means 5 vertices (1 Hub + 4 Rim).\n\nRim is C4​. Hub connected to all 4 rim vertices.\nW4​=C4​+K1​ (Join of Cycle and Single Node).\n\n\nTo find W4​ˉ​:\n\nC4​+K1​​=C4​ˉ​∪K1​ˉ​.\nK1​ˉ​ is just an isolated vertex (C=1).\nC4​ˉ​ (Complement of square cycle):\n\nIn C4​, edges are (1,2),(2,3),(3,4),(4,1).\nIn C4​ˉ​, edges are the diagonals (1,3) and (2,4).\nThis forms two disjoint edges (2K2​).\nComponents in C4​ˉ​ = 2.\n\n\nTotal Components in W4​ˉ​=2+1=3.\n\n\n\nStep 3: Total Components\n\nComponents(Gˉ) = Components(C3​ˉ​) + Components(W4​ˉ​)\nTotal = 3+3=6.\n\nAnswer: 6 Components.\nVisual Representation\n1. Structure of Disconnected Compliment:\nThe graph Gˉ consists of:\n\n3 isolated vertices (from C3​ˉ​).\n1 isolated vertex (the hub of W4​).\n2 disjoint edges (the diagonals of the C4​ rim).\n\ngraph TD\n    subgraph C3_Complement\n        A((v1))\n        B((v2))\n        C((v3))\n    end\n    subgraph W4_Complement\n        Hub((Hub))\n        subgraph Rim_Diagonals\n            r1((r1)) --- r3((r3))\n            r2((r2)) --- r4((r4))\n        end\n    end\n"},"DM/long/Graph_Theory_Planarity":{"slug":"DM/long/Graph_Theory_Planarity","filePath":"DM/long/Graph_Theory_Planarity.md","title":"Graph_Theory_Planarity","links":["tags/gate","tags/dm","tags/long","tags/graphs"],"tags":["gate","dm","long","graphs"],"content":"gate dm long graphs\nPlanarity\nPlanar Graph\nIf we can draw a graph such that no two edges intersect each other (except at vertices), we call it a Planar Graph.\nDrawing a planar graph on a plane without edge crossings is called a Planar Embedding.\nKey Non-Planar Graphs\nK5​ (Kuratowski’s First Graph)\nK5​ is the complete graph on 5 vertices. It is the non-planar graph with the minimum number of vertices.\n\nVertices (n): 5\nEdges (e): 10\nDegree of each vertex: 4 (Regular Graph)\n\n\n\n                  \n                  NOTE\n                  \n                \n\n(K5​−one edge) is a planar graph.\n\n\ngraph TD\n    A(((A))) --- B(((B)))\n    A --- C(((C)))\n    A --- D(((D)))\n    A --- E(((E)))\n    B --- C\n    B --- D\n    B --- E\n    C --- D\n    C --- E\n    D --- E\n    %% This is a visual representation of connections; inherently K5 cannot be drawn planar here.\n\nK3,3​ (Kuratowski’s Second Graph)\nK3,3​ is the complete bipartite graph. It is the non-planar graph with the minimum number of edges.\n\nVertices (n): 6\nEdges (e): 9\nDegree of each vertex: 3 (3-Regular Graph)\n\n\n\n                  \n                  NOTE\n                  \n                \n\n(K3,3​−one edge) is a planar graph.\n\n\ngraph TD\n    subgraph Set1\n    A((A))\n    B((B))\n    C((C))\n    end\n    subgraph Set2\n    1((1))\n    2((2))\n    3((3))\n    end\n    A --- 1\n    A --- 2\n    A --- 3\n    B --- 1\n    B --- 2\n    B --- 3\n    C --- 1\n    C --- 2\n    C --- 3\n\n\nRegions (Faces)\nWhen a planar graph is drawn on a plane, it divides the plane into regions (or faces).\n\nBounded/Finite Region: Enclosed by edges.\nUnbounded/Infinite Region: The outer region surrounding the graph. There is always exactly one unbounded region.\n\nEuler’s Formula\nFor a connected planar graph:\nn−e+f=2\nWhere:\n\nn: Number of vertices\ne: Number of edges\nf: Number of faces (regions)\n\n\n\n                  \n                  IMPORTANT\n                  \n                \n\nFor disconnected graphs with k components:\nn−e+f=k+1\n\n\n\nDegree of Regions (d(Ri​))\nThe degree of a region is the number of edges bordering that region.\n\nIf an edge is part of a cycle, it borders two different regions.\nIf an edge is a bridge (cut-edge), it borders the same region twice (contributes 2 to the degree).\n\nExample:\nConsider a graph with a triangle ABC inside a larger cycle.\ngraph TD\n    A --- B\n    B --- C\n    C --- A\n    A --- D\n    B --- D\n\n(Hypothetical example for calculation logic)\nSummation Property:\n∑i=1f​d(Ri​)=2e\nReason: Each edge contributes exactly 2 to the sum of degrees of regions (either bordering two different regions or the same region twice).\n\nImportant Inequalities\n1. General Planar Graphs (e≤3n−6)\nSince each region is bounded by at least 3 edges (a triangle is the minimal closed region):\nd(Ri​)≥3\nSumming for all f regions:\n∑d(Ri​)≥3f\nUsing ∑d(Ri​)=2e:\n2e≥3f⟹f≤32e​\nSubstitute into Euler’s formula (n−e+f=2):\nn−e+32e​≥2\nn−3e​≥2\n3n−e≥6\ne≤3n−6\n\n\n                  \n                  TIP\n                  \n                \n\nContrapositive (Non-Planar Check):\nIf e&gt;3n−6, then the graph is Non-Planar.\nNote: e≤3n−6 is a necessary condition, not sufficient.\n\n\n2. Triangle-Free Graphs (e≤2n−4)\nIf a graph has no triangles (e.g., Bipartite Graphs), then every region must be bounded by at least 4 edges (smallest cycle length is 4).\nd(Ri​)≥4\n∑d(Ri​)≥4f⟹2e≥4f⟹f≤2e​\nSubstitute into Euler’s formula:\nn−e+2e​≥2\nn−2e​≥2\n2n−e≥4\n2n−4≥eore≤2n−4\nExample Application:\nCheck K3,3​ (n=6,e=9). It is bipartite (no triangles).\nLHS=e=9\nRHS=2(6)−4=8\nSince 9≤8, K3,3​ is Non-Planar.\n\nMinimum Degree Theorem\nTheorem: If G is a connected planar graph, then δ(G)≤5 (Minimum degree is at most 5).\nProof:\nWe know sum of degrees =2e.\n∑v∈V​deg(v)=2e\nAlso, e≤3n−6.\nAverage degree =n2e​≤n2(3n−6)​=n6n−12​=6−n12​&lt;6.\nSince the average degree is strictly less than 6, there must be at least one vertex with degree ≤5.\n\nRelevant PYQs\nGATE CSE 2014 Set 1\nQuestion: Let G be a connected planar graph with 10 vertices. If the number of edges on each face is three, then the number of edges in G is ____.\nSolution:\nHere, every face is bounded by 3 edges, so d(Ri​)=3 for all i.\nSum of region degrees: ∑d(Ri​)=3f.\nWe know ∑d(Ri​)=2e.\nSo, 3f=2e⟹f=32e​.\nUsing Euler’s Formula:\nn−e+f=2\n10−e+32e​=2\n8=e−32e​=3e​\ne=24\n"},"DM/long/Predicate_Logic_Basics_Long":{"slug":"DM/long/Predicate_Logic_Basics_Long","filePath":"DM/long/Predicate_Logic_Basics_Long.md","title":"Predicate_Logic_Basics_Long","links":["tags/dm","tags/long","tags/logic","tags/predicate_logic"],"tags":["dm","long","logic","predicate_logic"],"content":"Predicate Logic Basics\nDate: 06/02/2026\n#gate dm long logic predicate_logic\nYouTube Link: Lecture 9\n\n1. Introduction\nOpen Statements: Statements that contain variables. Their truth value depends on the value assigned to the variables.\n\nExample: x is an even number. (Truth value depends on x)\n\nPropositional Statements: Statements with a fixed truth value (True or False).\n\nExample: 2 is an even number. (True)\n\nPredicate Variable:\nA symbol (like P,Q,R) used to represent a property or a relation.\nIn P(x), P is the predicate denoting the property (e.g., “is even”) and x is the subject. The predicate remains constant while the subject varies.\nDomain / Universe of Discourse (D):\nThe set of all possible values that the variable can take.\n\nExample: D={0,1,2}, P(x)=x is even.\n\nP(0)→T\nP(1)→F\nP(2)→T\n\n\n\n\n2. Quantifiers\nQuantifiers are tools used to define the truth value of an open statement over a domain in terms of quantity.\n2.1 Universal Quantifier (∀)\n\nSymbol: ∀ (For all, for every, for each)\nDefinition: The statement ∀xP(x) is True if and only if P(x) is true for every element in the domain.\nIt is False if there is at least one element for which P(x) is false (Counterexample).\nLogical Equivalence: ∀xP(x)≡P(x1​)∧P(x2​)∧⋯∧P(xn​) (AND relation).\n\n2.2 Existential Quantifier (∃)\n\nSymbol: ∃ (There exists, for some, at least one)\nDefinition: The statement ∃xP(x) is True if P(x) is true for at least one element in the domain.\nIt is False if P(x) is false for all elements.\nLogical Equivalence: ∃xP(x)≡P(x1​)∨P(x2​)∨⋯∨P(xn​) (OR relation).\n\n\n3. Practice Questions (Truth Values)\nQ1. Domain D:Z (Integers)\n∀x(x2≥0)\n\nAnswer: TRUE. Square of any integer is non-negative.\n\nQ2. Domain D:{1,2,3}\n∃x(x2=4)\n\nAnswer: TRUE. For x=2, 22=4.\n\nQ3. Domain D:{1,2,3}\n∀x(x2=4)\n\nAnswer: FALSE. For x=1, 12=4.\n\nQ4. Domain D:Z\n∃n(n2≤10)\n\nAnswer: TRUE. For n=1,2,3, it holds.\n\nQ5. Domain D:Z\n∀x(x2≤x)\n\nAnswer: FALSE. For x=2, 4≤2 is False.\n\nQ6. Domain D:N (Natural Numbers)\n∀x(x+1&gt;x)\n\nAnswer: TRUE.\n\nQ7. Domain D:R (Real Numbers)\n∃x(x2=−1)\n\nAnswer: FALSE. No real number squared is negative.\n\n\n4. Logical Distributivity &amp; Implications\nWe can analyze the relationship between operands (∧,∨) and quantifiers.\n4.1 Existential over AND (∃ and ∧)\nStatement: ∃x[P(x)∧Q(x)]⟹∃xP(x)∧∃xQ(x)\n\nValidity: TRUE\nProof:\nLet LHS be True. Then there exists some c∈D such that P(c)∧Q(c) is True.\nThis implies P(c) is True ⟹∃xP(x) is True.\nAlso Q(c) is True ⟹∃xQ(x) is True.\nThus, RHS is True.\n\nStatement: ∃xP(x)∧∃xQ(x)⟹∃x[P(x)∧Q(x)]\n\nValidity: FALSE\nCounterexample:\nD={1,2}\nP(x):x=1\nQ(x):x=2\n∃xP(x) is True (at x=1).\n∃xQ(x) is True (at x=2).\nLHS is True.\nP(x)∧Q(x) is False for x=1 and False for x=2.\nSo ∃x[P(x)∧Q(x)] is False.\nT⟹F is False.\n\n4.2 Universal over AND (∀ and ∧)\nStatement: ∀x[P(x)∧Q(x)]⟺∀xP(x)∧∀xQ(x)\n\nValidity: TRUE (Both directions hold)\nIntuition: “Everyone likes Apples AND Oranges” is same as “Everyone likes Apples AND Everyone likes Oranges”.\n\n4.3 Existential over OR (∃ and ∨)\nStatement: ∃x[P(x)∨Q(x)]⟺∃xP(x)∨∃xQ(x)\n\nValidity: TRUE (Both directions hold)\n\n4.4 Universal over OR (∀ and ∨)\nStatement: ∀xP(x)∨∀xQ(x)⟹∀x[P(x)∨Q(x)]\n\nValidity: TRUE\nProof:\nIf All are P or All are Q, then definitely for any specific element, it is P or Q.\n\nStatement: ∀x[P(x)∨Q(x)]⟹∀xP(x)∨∀xQ(x)\n\nValidity: FALSE\nCounterexample:\nD={1,2}\nP(x):x=1, Q(x):x=2\nFor x=1: P(1)∨Q(1) is T∨F=T.\nFor x=2: P(2)∨Q(2) is F∨T=T.\nLHS is True.\n∀xP(x) is False. ∀xQ(x) is False.\nRHS is False.\n\n\n5. Relevant PYQs\nGATE CSE 2023 | Question: 16\nGeetha’s Conjecture: ∀x(P(x)⟹∃yQ(x,y))\nWhich options imply Geetha’s conjecture?\n\n(A) ∃x(P(x)∧∀yQ(x,y))\n(B) ∀x∀yQ(x,y)\n(C) ∃y∀x(P(x)⟹Q(x,y))\n(D) ∃x(P(x)∧∃yQ(x,y))\n\nLink to Discussion\n\nGATE IT 2008 | Question: 22\nWhich of the following is the negation of [∀x,α→(∃y,β→(∀u,∃v,y))]?\n(Note: α,β,y in question likely refer to predicates or logical structure, need to parse carefully from source if ambiguous, but standard negation rules apply).\nLink to Discussion"},"DM/long/Propositional_Logic_Notes":{"slug":"DM/long/Propositional_Logic_Notes","filePath":"DM/long/Propositional_Logic_Notes.md","title":"Propositional_Logic_Notes","links":["tags/gate","tags/dm","tags/long","tags/logic","tags/propositional_logic"],"tags":["gate","dm","long","logic","propositional_logic"],"content":"gate dm long logic propositional_logic\nPropositional Logic\nDate: 03/02/2026\nYoutube Link: Lecture\n\nIntroduction to Logic\nIn logic, we deal with statements (or propositions) that can be clearly classified as True (T) or False (F).\nStatements can be divided into two types:\n\nSimple Statements: A statement that cannot be broken down into smaller statements.\n\nExample: “It is raining.” (p)\n\n\nCompound Statements: A statement formed by combining two or more simple statements using logical connectives.\n\nExample: “It is raining AND I will take an umbrella.” (p∧q)\n\n\n\nbasically the statements which give us a proposition.\n\nLogical Connectives\nConnectives are used to join simple statements to form compound statements. The four main connectives are:\n1. Conjunction (AND) - (∧)\nThe statement p∧q is True only when both p and q are True.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npqp∧qTTTTFFFTFFFF\n2. Disjunction (OR) - (∨)\nThe statement p∨q is False only when both p and q are False. (This is inclusive OR).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npqp∨qTTTTFTFTTFFF\n3. Single Implication (If… Then) - (→)\nThe statement p→q is False only when p is True (Antedecent) and q is False (Consequent). In all other cases, it is True.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npqp→qTTTTFFFTTFFT\n4. Double Implication (If and only if) - (↔)\nThe statement p↔q is True when both p and q have the same truth value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npqp↔qTTTTFFFTFFFT\n\nClassification of Propositions\nSatisfiable Expression\nAn expression is Satisfiable if the result of the expression is True for at least one combination of input values.\n\nNote: All Tautologies and Contingencies are Satisfiable.\n\nTautology (Valid Expression)\nAn expression is a Tautology if the result is True (T) for ALL possible combinations of input values.\n\nRule: All Valids are Satisfiable, but not all Satisfiables are Valid.\nNotation: ⊨P\n\nContradiction (Unsatisfiable)\nAn expression is a Contradiction if the result is False (F) for ALL possible combinations of input values.\nContingency\nAn expression is a Contingency if the result contains a mixture of True and False values (neither a Tautology nor a Contradiction).\n\nRule: All Contingencies are Satisfiable.\n\n\nExample Problem: Tautology Check\nQuestion: Is the following expression a Tautology?\n[a∧(a→b)∧(¬b∨c)]→c\nSolution (Proof by Falsification):\nInstead of drawing a full truth table (which would have 23=8 rows), we can try to prove the expression is FALSE. If we fail to make it False (i.e., we encounter a contradiction in our assumption), then it must be a Tautology.\n\n\nAssume the expression is FALSE.\nFor an implication X→Y to be False, we must have X is True and Y is False.\n\nSo, let c=F (False).\nAnd [a∧(a→b)∧(¬b∨c)] must be True.\n\n\n\nAnalyze the Left Side (Antecedent):\nSince it is a conjunction (AND), for it to be True, all parts must be True:\n\na=T\n(a→b)=T\n(¬b∨c)=T\n\n\n\nEvaluate Step-by-Step:\n\nWe already found c=F.\nLook at (¬b∨c). Since c is False, for the OR statement to be True, ¬b must be True.\n\n⟹¬b=T⟹b=F.\n\n\nWe already found a=T.\nNow check (a→b) with a=T and b=F.\n\n(T→F) results in False.\n\n\n\n\n\nContradiction:\nWe assumed the antecedent was True, which required (a→b) to be True. However, our derived values (a=T,b=F) make (a→b) False.\nThis is a contradiction.\n\n\nConclusion:\nIt is impossible to make the expression False. Therefore, the expression is a Tautology.\n\n\n\nInference Rules\nIn an inference rule, the left side of the implication is called the Premises (or Antecedent) and the right side is called the Conclusion (or Consequent).\nWe consider the premises as True, then check the conclusion:\n\nIf the conclusion is True, it follows the inference rule (Valid).\nIf the conclusion is False, it does not follow the inference rule (Invalid).\n\nExample: Disjunctive Syllogism\nPremises:\n\nP1​: Mobile phone is in left OR right pocket. (True)\nP2​: It is NOT in the left pocket. (True)\n\nConclusion:\n\nQ: It MUST be in the right pocket. (True)\n\nLogical Form:\nLet L = “Phone is in Left pocket”\nLet R = “Phone is in Right pocket”\n\nP1​:L∨R\nP2​:¬L\n∴R\n\nExplanation:\nIf we know that at least one of L or R is true (L∨R), and we find out that L is specifically false (¬L), the only remaining possibility for the first statement to hold true is for R to be true. Thus, R is a valid conclusion. This is a standard inference rule known as Disjunctive Syllogism.\nStandard Logical Identities and Inference Rules\n(Refer to the image below for visual derivations)\n\nSome key rules derivation shown in the image (recreated below):\n\n\nModus Ponens\n[a∧(a→b)]→b\n\nPremise 1: a→b\nPremise 2: a\nConclusion: b\n\n\n\nModus Tollens\n[(a→b)∧¬b]→¬a (derived from contrapositive)\n\n\nDisjunctive Syllogism\n[(a∨b)∧¬a]→b\n\nPremise 1: a∨b\nPremise 2: ¬a\nConclusion: b\n\n\n\nHypothetical Syllogism\n[(a→b)∧(b→c)]→(a→c)\n\nPremise 1: a→b\nPremise 2: b→c\nConclusion: a→c\n\n\n\nResolution\n[(a∨b)∧(¬b∨c)]→(a∨c)\n\n\n\nRelevant PYQs\nGATE IT 2008 | Question 1\nQuestion:\nIf A→BC and A→B then A→C.\nExactly how many of the above implications are valid?\n(A) 0\n(B) 1\n(C) 2\n(D) 3\nDiscussion Link\n"},"DM/long/Quantifiers_Logic":{"slug":"DM/long/Quantifiers_Logic","filePath":"DM/long/Quantifiers_Logic.md","title":"Quantifiers_Logic","links":["tags/gate","tags/dm","tags/long","tags/logic","tags/predicate_logic","tags/quantifiers"],"tags":["gate","dm","long","logic","predicate_logic","quantifiers"],"content":"Quantifiers: Nested &amp; Implications\nDate: 10/02/2026\nTags: gate dm long logic predicate_logic quantifiers\nYouTube Link: Lecture 8\n\n1. Important Equivalence &amp; Implication Rules\nWe learned how quantifiers interact with logical connectives (∧,∨,→).\n1.1 Strong Equivalences (Distributive)\nThese hold true in both directions (≡):\n\n\nUniversal over AND:\n∀x[P(x)∧Q(x)]≡∀xP(x)∧∀xQ(x)\nMeaning: “Everyone is smart AND kind” is the same as “Everyone is smart AND Everyone is kind”.\n\n\nExistential over OR:\n∃x[P(x)∨Q(x)]≡∃xP(x)∨∃xQ(x)\nMeaning: “Someone is smart OR kind” is the same as “Someone is smart OR Someone is kind”.\n\n\n1.2 One-Way Implications\nThese hold true only in one direction:\n\n\nExistential over AND:\n∃x[P(x)∧Q(x)]⟹∃xP(x)∧∃xQ(x)\n\nLogic: If there is someone who is BOTH smart and kind, then definitely “Someone is smart” AND “Someone is kind”.\nReverse is FALSE: Just because someone is smart and someone (else) is kind, doesn’t mean there is one person who is both.\n\n\n\nUniversal over OR:\n[∀xP(x)∨∀xQ(x)]⟹∀x[P(x)∨Q(x)]\n\nLogic: If “Everyone is smart” OR “Everyone is kind”, then definitely “Everyone is either smart or kind”.\nReverse is FALSE: “Everyone is either male or female” does NOT mean “Everyone is male OR Everyone is female”.\n\n\n\nUniversal over Implication:\n∀x[P(x)→Q(x)]⟹[(∀xP(x))→(∀xQ(x))]\n\n\nUniversal over Biconditional:\n∀x[P(x)↔Q(x)]⟹[(∀xP(x))↔(∀xQ(x))]\n\n\n\n2. Nested Quantifiers\nWhen we have multiple quantifiers (e.g., ∀x∃y), the order matters unless they are of the same type.\n2.1 Same Quantifiers (Commutative)\n\n∀x∀yP(x,y)≡∀y∀xP(x,y)\n∃x∃yP(x,y)≡∃y∃xP(x,y)\n\n2.2 Mixed Quantifiers (Non-Commutative)\nOrder changes the meaning entirety!\nExample Domain: D={1,2,3}\nStatement: x⋅y≥0 (assuming non-negative domain usually, but let’s say Z+).\n\n∀x∀y(x⋅y≥0): For all x, for all y, product is positive. (True if domain Z+).\n∀x∃y(x+y=10): For every x, there corresponds some y. (True in Real numbers/Integers).\n\nInterpretation: y can depend on x. If x=1,y=9. If x=2,y=8.\n\n\n∃y∀x(x+y=10): There is one specific y that works for all x.\n\nInterpretation: Impossible in integers. If y=5, then x+5=10 only for x=5, not for all x. FALSE.\n\n\n\n\n3. The Power Hierarchy (Most Important)\nThere is a strict hierarchy of strength among nested quantifiers.\n∀x∀y⟹∃y∀x⟹∀x∃y⟹∃x∃y\nVisualization of Mapping\n\n∃y∀x (Stronger): There is a “Magic Key” y that opens all locks x.\n\nOne-to-All relationship.\n\n\n∀x∃y (Weaker): Every lock x has its own key y.\n\nAll-to-Some relationship.\n\n\n\ngraph TD\n    A[∀x ∀y] --&gt;|Implies| B[∃y ∀x]\n    B --&gt;|Implies| C[∀x ∃y]\n    C --&gt;|Implies| D[∃x ∃y]\n    \n    style A fill:#f9f,stroke:#333\n    style B fill:#bbf,stroke:#333,stroke-width:4px\n    style C fill:#bbf,stroke:#333,stroke-width:4px\n    style D fill:#f9f,stroke:#333\n\nWhy ∃y∀x⟹∀x∃y?\nIf there is one special person y (say, a Chef) who cooks for everyone (∀x), then it is automatically true that “Everyone (∀x) has someone (∃y) who cooks for them” (which happens to be that same Chef).\n\nLHS: One y for all x.\nRHS: For each x, there is a y.\n\n\n4. Relevant Questions\nQ1. Valid Formula Check\nQuestion: Which of the following is valid?\n\n∀x(P(x)→Q(x))→(∀xP(x)→∀xQ(x))\n∃x(P(x)∨Q(x))→(∃xP(x)→∃xQ(x))\n\nAnswer:\n\nValid. This matches our rule. If P implies Q for everyone, then if everyone is P, everyone must be Q.\nInvalid.\n\nQ2. Convergent Sequence Logic (GATE)\nThe statement “The sequence converges to a limit” can be written as:\n∀ϵ&gt;0,∃N,∀n&gt;N,∣xn​−L∣&lt;ϵ\nNotice the alternating quantifiers ∀∃∀. Changing their order destroys the definition.\nQ3. Graph Theory Connection\n\n∀x∃y(x is connected to y): Every node has at least one neighbor (No isolated vertices).\n∃y∀x(x is connected to y): There is a “Master Node” connected to everyone (Star Graph center).\n\nThis clearly shows ∃y∀x⟹∀x∃y (A star center implies no isolated vertices), but not vice versa."},"DM/long/Set_Theory_Relations":{"slug":"DM/long/Set_Theory_Relations","filePath":"DM/long/Set_Theory_Relations.md","title":"Set_Theory_Relations","links":["DM/short/Set_Theory_Relations_Short"],"tags":["gate","dm","relations","sets","long"],"content":"Set Theory - Relations Basics\nShort Notes\nIntroduction\nIn Set Theory, a Relation is a way to describe a connection between elements of sets.\nGiven two sets A and B, the Cartesian Product A×B is the set of all ordered pairs (a,b) where a∈A and b∈B.\nA×B={(a,b)∣a∈A,b∈B}\nA Relation R from set A to set B is a subset of the Cartesian product A×B.\nR⊆A×B\nIf (a,b)∈R, we say ”a is related to b” and denote it as aRb.\nRelations on a Single Set\nMost often, we talk about a relation on a single set A, which means R⊆A×A.\n\nCounting Relations\nTotal Number of Relations from A to B\nLet ∣A∣=m and ∣B∣=n.\nThe number of elements in A×B is ∣A×B∣=m⋅n.\nSince a relation is any subset of A×B, the total number of possible relations is the number of subsets of A×B, which is the power set size.\nTotal Relations=2∣A×B∣=2mn\nTotal Number of Relations on A\nLet ∣A∣=n.\nThen ∣A×A∣=n2.\nTotal number of relations on A is:\nTotal Relations=2n2\n\nTypes of Relations\n1. Reflexive Relation\nA relation R on set A is Reflexive if every element of A is related to itself.\n∀a∈A,(a,a)∈R\nExample:\nA={1,2,3}\nR={(1,1),(2,2),(3,3),(1,2)} is Reflexive because (1,1),(2,2),(3,3) are all present.\nR′={(1,1),(2,2)} is Not Reflexive because (3,3)∈/R′.\nCounting Reflexive Relations:\nTo form a reflexive relation, all n diagonal elements {(a,a)∣a∈A} must be included.\nThe remaining n2−n off-diagonal elements can either be in the set or not (2 choices each).\nNumber of Reflexive Relations=1n⋅2n2−n=2n2−n\n2. Symmetric Relation\nA relation R is Symmetric if for every pair (a,b)∈R, the pair (b,a) is also in R.\n∀a,b∈A,((a,b)∈R⟹(b,a)∈R)\nInformal check: If you flip every pair in the relation, you should get the same set of pairs back.\nExample:\nA={1,2,3}\nR={(1,2),(2,1),(3,3)} is Symmetric.\nR′={(1,2)} is Not Symmetric because (2,1)∈/R′.\nCounting Symmetric Relations:\n\nDiagonal elements (a,a): We have n such elements. Each can be present or absent (2 choices). Total 2n ways.\nOff-diagonal pairs {(a,b),(b,a)} with a=b: There are n2−n off-diagonal elements, forming 2n2−n​ pairs. For symmetry, if (a,b) is chosen, (b,a) must be chosen. So for each pair, we have 2 choices (both present or both absent).\nTotal ways = 2n⋅22n2−n​=222n+n2−n​=22n2+n​.\n\nNumber of Symmetric Relations=22n(n+1)​\n3. Anti-symmetric Relation\nA relation R is Anti-symmetric if no two distinct elements are related to each other in both directions.\n∀a,b∈A,((a,b)∈R∧(b,a)∈R⟹a=b)\nAllowed: (a,b) only, (b,a) only, or neither.\nNot Allowed: Both (a,b) and (b,a) if a=b.\nDiagonal elements (a,a) are always allowed.\nExample:\nA={1,2,3}\nR={(1,2),(2,3)} is Anti-symmetric.\nR′={(1,2),(2,1)} is Not Anti-symmetric.\nCounting Anti-symmetric Relations:\n\nDiagonal elements (a,a): n elements, 2 choices each (present/absent). Total 2n.\nOff-diagonal pairs {(a,b),(b,a)}: There are 2n2−n​ such pairs. For each pair, we have 3 allowed choices:\n\nOnly (a,b) is in R.\nOnly (b,a) is in R.\nNeither is in R.\n\n\nNote: We cannot have both.\n\n\nTotal ways = 2n⋅32n2−n​.\n\nNumber of Anti-symmetric Relations=2n⋅32n2−n​\n\nOperations on Relations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPropertyUnion (R1​∪R2​)Intersection (R1​∩R2​)ReflexiveReflexiveReflexiveSymmetricSymmetricSymmetricAnti-symmetricNot GuaranteedAnti-symmetric\n\nNote on Reflexive Intersection: If R1​ and R2​ are reflexive, then for all a, (a,a)∈R1​ and (a,a)∈R2​. Thus (a,a)∈R1​∩R2​. So the intersection is always reflexive.\n\n\nNote on Anti-symmetric Union: If R1​={(1,2)} and R2​={(2,1)}, both are anti-symmetric. But R1​∪R2​={(1,2),(2,1)} which is not anti-symmetric.\n\n\nDetailed Derivations &amp; Explanations\nWhy 2n2 relations?\nThink of the relation as an n×n adjacency matrix (0 or 1).\nA relation can be represented by a matrix M where Mij​=1 if (i,j)∈R and 0 otherwise.\nThere are n2 entries in the matrix. Each entry can be 0 or 1 (2 choices).\nTotal possibilities = n2 times2×2×⋯×2​​=2n2.\nWhy Reflexive is 2n2−n?\nFor a matrix to represent a reflexive relation, the main diagonal (entries Mii​) must all be 1.\n\nDiagonal entries: 1 choice each (must be 1).\nOff-diagonal entries: n2−n entries remaining. Each has 2 choices (0 or 1).\nTotal = 1n×2n2−n=2n2−n.\n\nWhy Symmetric is 2(n2+n)/2?\nFor a symmetric matrix, Mij​=Mji​.\n\nThe diagonal entries Mii​ are independent (2 choices each). Total n.\nThe upper triangle entries determine the lower triangle. There are 2n2−n​ entries in the upper triangle.\nOnce you choose the upper triangle and diagonal, the relation is fixed.\nTotal independent choices = n (diagonal) + 2n2−n​ (upper triangle) = 22n+n2−n​=2n2+n​.\nTotal relations = 22n(n+1)​.\n\nWhy Reflexive AND Symmetric is 2(n2−n)/2?\n\nReflexive: Diagonal is fixed to 1 (1 choice).\nSymmetric: Upper triangle determines lower triangle.\nUpper triangle entries: 2n2−n​ entries, 2 choices each.\nTotal = 1n×22n2−n​=22n2−n​.\n\n\nRelevant PYQs\nGATE CSE 2021 Set 1 | Question: 43\nDiscussion Link\nA relation $R$ is said to be circular if $a\\text{R}b$ and $b\\text{R}c$ together imply $c\\text{R}a$.\nWhich of the following options is/are correct?\n\nIf a relation $S$ is reflexive and symmetric, then $S$ is an equivalence relation.\nIf a relation $S$ is circular and symmetric, then $S$ is an equivalence relation.\nIf a relation $S$ is reflexive and circular, then $S$ is an equivalence relation.\nIf a relation $S$ is transitive and circular, then $S$ is an equivalence relation.\n\nAnalysis:\n\nAn Equivalence Relation is Reflexive, Symmetric, and Transitive.\nThis question tests properties like circularity combined with others.\n(C) If Reflexive (aRa) and Circular (aRb∧bRc⟹cRa), we can prove Symmetry and Transitivity.\n\nSymmetry: aRa∧aRb⟹bRa (using circular with c=a). So Reflexive + Circular ⟹ Symmetric.\nTransitivity: aRb∧bRc⟹cRa. Since Symmetric, cRa⟹aRc. So aRb∧bRc⟹aRc. Transitive.\nThus Reflexive + Circular ⟹ Equivalence. Correct.\n\n\n\n"},"DM/short/Graph_Theory_Adjacency_Matrix_Short":{"slug":"DM/short/Graph_Theory_Adjacency_Matrix_Short","filePath":"DM/short/Graph_Theory_Adjacency_Matrix_Short.md","title":"Graph_Theory_Adjacency_Matrix_Short","links":["tags/gate","tags/dm","tags/short","tags/graphs","DM/long/Graph_Theory_Adjacency_Matrix"],"tags":["gate","dm","short","graphs"],"content":"gate dm short graphs\nAdjacency Matrix (Short Notes)\nLink to Long Notes: Graph_Theory_Adjacency_Matrix\nBasics\n\nAdjacency Matrix A: n×n matrix. Aij​=1 agar edge hai i aur j ke beech, else 0 (for simple unweighted graphs).\nSymmetric: Undirected graphs ke liye A symmetric hota hai (Aij​=Aji​).\nPrincipal Diagonal: All 0s agar self-loops nahi hain.\n\nProperties (Important for GATE)\n\n\nDegree Calculation:\n\nRow ya Column ka sum = Vertex ki degree.\n∑Aij​=deg(vi​).\n\n\n\nPowers of Matrix (Ak):\n\n(Ak)ij​= Number of walks of length k from i to j.\nA2 (Square):\n\nDiagonal entry (A2)ii​= Degree of vertex i.\nTrace(A2)=2×∣E∣ (Sum of degrees).\n\n\nA3 (Cube):\n\nDiagonal entry (A3)ii​ relates to triangles.\nTrace(A3)=6×(Number of Triangles).\n\n\n\n\n\nEigenvalues (Spectrum):\n\nSum of Eigenvalues (∑λi​) = 0 (Trace is 0).\nSum of Squares (∑λi2​) = 2×∣E∣.\nSum of Cubes (∑λi3​) = 6×Triangles.\n\n\n\nConnectivity &amp; Matrix\n\nAgar graph Connected hai, toh (I+A)n−1 ke saare entries positive honge.\nReasoning: Walks of all lengths up to n−1 cover ho jate hain.\n\nGenerating Function Analogy\n\nJaise 1−x1​=1+x+x2+…\nWaise hi (I−A)−1 connects to walks of all lengths.\n(I+A)n−1 ensures connectivity check efficiently.\n\n\nFun Fact (Eigenvalues):\nThink of Matrix as a machine.\n\nEigenvectors = Arrow directions jo turn nahi hote (sirf stretch/shrink hote hain).\nEigenvalues = Wo stretch/shrink factor.\n\n\nRelevant PYQs\n\nGATE IT 2005: Matrix properties vs Connectivity.\nGATE CSE 2022: Connected components and Eigenvalues.\n"},"DM/short/Graph_Theory_Basics_Short":{"slug":"DM/short/Graph_Theory_Basics_Short","filePath":"DM/short/Graph_Theory_Basics_Short.md","title":"Graph_Theory_Basics_Short","links":["tags/gate","tags/dm","tags/short","tags/graphs"],"tags":["gate","dm","short","graphs"],"content":"gate dm short graphs\nGraph Theory - Basics Summary (Hinglish)\nDate: 27/01/2026\n1. Graph Basics G=(V,E)\n\nVertex (V): Point, Join.\nEdge (E): Line, Branch.\nDegree (d(v)): “Welding points”. Ek vertex se kitni edges judi hain.\n\n2. Important Theorems\n\n\nHandshaking Lemma:\n∑d(vi​)=2×∣E∣\nMatlab: Sum of degrees hmesha EVEN hoga.\n\n\nOdd Degree Vertices:\nTotal sum even hai, toh Odd degree wale vertices ka sum bhi even hona chahiye.\nConclusion: Number of odd degree vertices = EVEN count.\n\n\nSimple Graph Rules:\n\nNo loops (khud se connection).\nNo parallel edges (multiple lines between same points).\n\n\n\nMax Limits (Simple Graph):\n\nMax degree of a vertex: n−1\nMax number of edges: 2n(n−1)​\n\n\n\nAverage Degree:\nn2∣E∣​\nInequality: Min Degree ≤ Avg ≤ Max Degree ≤n−1\n\n\n3. Havel-Hakimi Procedure (Check Graphical Sequence)\nAgar check krna hai ki koi degree sequence valid simple graph bnata hai ya nahi:\n\nSort descending (bada pehle).\nFirst element k ko remove karo.\nNext k elements me se -1 karo.\nWapis sort karo aur repeat karo.\nAgar end me sab 0 aa jaye → Graphical hai.\nAgar negative aa jaye → Graphical nahi hai.\n\n4. Total Possible Graphs\nSimple graph me har edge hone ya na hone ki probability hai.\nMax edges Emax​=2n(n−1)​ hote hain.\nSo, total graphs possible = 2Emax​\n=22n(n−1)​\n\n5. Special Types of Graphs\n1. Complete Graph (Kn​) (n≥1)\n\nDefinition: Har vertex har dusre vertex se directly connected hota hai.\nDegree: Each vertex has degree n−1.\nEdges: ∣E∣=2n(n−1)​\nExample (K4​):\n\ngraph TD\n    A --- B\n    A --- C\n    A --- D\n    B --- C\n    B --- D\n    C --- D\n\n2. Regular Graph\n\nDefinition: Har vertex ki degree same hoti hai (k-Regular).\nCondition: δ(G)=Avg Degree=Δ(G)=k\nFormula: k=n2∣E∣​\nExample: Kn​ is (n−1)-regular. Cn​ is 2-regular.\n\n3. Cycle Graph (Cn​) (n≥3)\n\nDefinition: Closed loop.\nDegree: Har vertex ki degree 2 hoti hai.\nEdges: ∣E∣=∣V∣=n\nNote: All Cn​ are regular graphs, but not all 2-regular graphs are Cn​ (disconnected cycles possible).\nExample (C4​):\n\ngraph TD\n    A --- B\n    B --- C\n    C --- D\n    D --- A\n\n4. Wheel Graph (Wn​) (n≥4)\n\nConstruction: Take a Cycle Graph Cn−1​ (rim) and add a central hub vertex connected to all rim vertices.\nEdges: (n−1) from cycle + (n−1) spokes = 2(n−1)\nDegree:\n\nHub vertex: n−1\nRim vertices: 3\n\n\nTheorem: 3(n−1)+(n−1)=2×2(n−1) (Handshaking verified)\nExample (W5​): (Derived from C4​ + Center)\n\ngraph TD\n    Center((Center))\n    A --- B\n    B --- C\n    C --- D\n    D --- A\n    Center --- A\n    Center --- B\n    Center --- C\n    Center --- D\n\n5. Bipartite Graph\n\nDefinition: Vertices ko 2 sets (V1​,V2​) me divide kr skte hain jahan edges sirf V1​ se V2​ ke beech hoti hain (same set me nahi).\nProperty: No odd length cycles.\nComplete Bipartite (Km,n​):\n\nV1​ has m vertices, V2​ has n.\nTotal Vertices: m+n\nTotal Edges: m×n\n\n\nExample (K2,3​):\n\ngraph TD\n    subgraph Set1\n    A(A)\n    B(B)\n    end\n    subgraph Set2\n    1(1)\n    2(2)\n    3(3)\n    end\n    A --- 1\n    A --- 2\n    A --- 3\n    B --- 1\n    B --- 2\n    B --- 3\n\n6. Hypercube (Qn​) (n≥1)\n\nVertices: Represented as n-bit strings. Total vertices 2n.\nEdges: Connect vertices that differ by exactly 1 bit.\nDegree: Each vertex has degree n (n-Regular).\nTotal Edges: 2n×2n​=n2n−1\nNote: Every hypercube is a Bipartite Graph.\n\n7. Complement Graph (Gˉ or G′)\n\nDefinition: Edges jo G me hain wo Gˉ me nahi hongi, aur vice versa.\nProperty: G+Gˉ=Kn​ (Complete Graph)\nEdges: ∣E(G)∣+∣E(Gˉ)∣=2n(n−1)​\n\n8. Self-Complement Graph\n\nDefinition: G≅Gˉ (Graph is isomorphic to its complement).\nFormula: Since ∣E(G)∣=∣E(Gˉ)∣:\n2∣E∣=2n(n−1)​⟹∣E∣=4n(n−1)​\nCondition: n(n−1) must be divisible by 4 (i.e., n≡0(mod4) or n≡1(mod4)).\n\n9. Line Graph L(G)\n\nDefinition: Edges of G become Vertices of L(G). Connect them if original edges shared a common vertex.\n\n\nRelevant PYQs\nGATE CSE 2010 | Question: 28\nDiscussion Link\nThe degree sequence of a simple graph is the sequence of the degrees of the nodes in the graph in decreasing order. Which of the following sequences can not be the degree sequence of any graph?\n\n$7, 6, 5, 4, 4, 3, 2, 1$\n$6, 6, 6, 6, 3, 3, 2, 2$\n$7, 6, 6, 4, 4, 3, 2, 2$\n$8, 7, 7, 6, 4, 2, 1, 1$\n\n\nI and II\nIII and IV\nIV only\nII and IV\n\n\nGATE CSE 2022 | Question: 20\nDiscussion Link\nConsider a simple undirected graph of 10 vertices. If the graph is disconnected, then the maximum number of edges it can have is _______________ .\n\nGATE CSE 2016 Set 1 | Question: 40\nDiscussion Link\n$G=(V, E)$ is an undirected simple graph in which each edge has a distinct weight, and $e$ is a particular edge of $G$. Which of the following statements about the minimum spanning trees $(MSTs)$ of $G$ is/are TRUE?\n\nIf $e$ is the lightest edge of some cycle in $G$, then every MST of $G$ includes $e$.\nIf $e$ is the heaviest edge of some cycle in $G$, then every MST of $G$ excludes $e$.\n\n\nI only.\nII only.\nBoth I and II.\nNeither I nor II.\n\n"},"DM/short/Graph_Theory_Connectivity_Short":{"slug":"DM/short/Graph_Theory_Connectivity_Short","filePath":"DM/short/Graph_Theory_Connectivity_Short.md","title":"Graph_Theory_Connectivity_Short","links":["tags/gate","tags/dm","tags/short","tags/graphs","tags/connectivity"],"tags":["gate","dm","short","graphs","connectivity"],"content":"gate dm short graphs connectivity\nGraph Theory - Connectivity (Short Notes)\nDate: 29/01/2026\n1. Quick Definitions\n\nWalk: Vertices &amp; Edges CAN repeat. (Bas ghumna hai).\nTrail: Vertices YES, Edges NO repeat.\nPath: Vertices NO, Edges NO repeat.\n\n2. Connectedness\n\nConnected: Path exists between every pair.\nComponent: Maximal connected subgraph.\nS1 (False): G connected ⟹Gˉ connected. (Ex: C4​ˉ​ is disconnected).\nS2 (True): G disconnected ⟹Gˉ Connected.\n\n3. Important Theorems\n\nMin Degree: If δ(G)≥2n−1​⟹ Connected.\nOdd Vertices: If exactly 2 odd degree vertices exist ⟹ Path exists between them (Same component).\n\n4. Edge Ranges\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraph TypeMin EdgesMax EdgesConnectedn−1 (Tree)(2n​) (Kn​)Disconnected (k comp)n−k2(n−k)(n−k+1)​\n5. Cuts &amp; Connectivity\n\nCut Edge (Bridge): Removal → Disconnected. (Must NOT be in a cycle).\nCut Vertex (Articulation): Removal → Disconnected.\nInequality Order:\nκ≤λ≤δ≤Avg≤Δ≤n−1\n(Vertex Conn ≤ Edge Conn ≤ Min Degree)\n\n6. Problem Trick: Complement of Join\nQuestion: (C3​+W4​)′ components?\n\nConcept: A+B​=Aˉ∪Bˉ (Disjoint Union).\nC3​ˉ​ (K3′​) → 3 isolated vertices (⟹ 3 comp).\nW4​ˉ​ (C4′​∪K1′​) →2K2​∪K1​ (⟹ 2 + 1 = 3 comp).\nTotal: 3+3=6 Components.\n\n\nRelevant PYQs (Connectivity)\nGATE1992-04-b\nDiscussion Link\nA priority encoder accepts three input signals (A, B and C) and produces a two-bit output (X1​,X0​) corresponding to the highest priority active input signal. Assume A has the highest priority followed by B and C has the lowest priority. If none of the inputs are active the output should be 00, design the priority encoder using 4:1 multiplexers as the main components.\n\nGATE IT 2008 | Question: 85\nDiscussion Link\nHost $X$ has $IP$ address $192.168.1.97$ and is connected through two routers $R1$ and $R2$ to an­other host $Y$ with $IP$ address $192.168.1.80$. Router $R1$ has $IP$ addresses $192.168.1.135$ and $192.168.1.110$. $R2$ has $IP$ addresses $192.168.1.67$ and $192.168.1.155$. The netmask used in the network is $255.255.255.224$.\nWhich $IP$ address should $X$ configure its gateway as?\n\n$192.168.1.67$\n$192.168.1.110$\n$192.168.1.135$\n$192.168.1.155$\n\n\nGATE IT 2008 | Question: 84\nDiscussion Link\nHost $X$ has IP address $192.168.1.97$ and is connected through two routers $R1$ and $R2$ to an­other host $Y$ with IP address $192.168.1.80$. Router $R1$ has IP addresses $192.168.1.135$ and $192.168.1.110$. $R2$ has IP addresses $192.168.1.67$ and $192.168.1.155$. The netmask used in the network is $255.255.255.224$.\nGiven the information above, how many distinct subnets are guaranteed to already exist in the network?\n\n$1$\n$2$\n$3$\n$6$\n\n\nGATE IT 2007 | Question: 63\nDiscussion Link\nA group of $15$ routers is interconnected in a centralized complete binary tree with a router at each tree node. Router $i$ communicates with router $j$ by sending a message to the root of the tree. The root then sends the message back down to router $j$. The mean number of hops per message, assuming all possible router pairs are equally likely is\n\n$3$\n$4.26$\n$4.53$\n$5.26$\n\n\nGATE IT 2007 | Question: 45\nDiscussion Link\nThe line $T$ in the following figure is permanently connected to the ground.\n\nWhich of the following inputs $(X_1 X_2 X_3 X_4)$ will detect the fault ?\n\n$0000$\n$0111$\n$1111$\nNone of these\n\n"},"DM/short/Graph_Theory_Planarity_Short":{"slug":"DM/short/Graph_Theory_Planarity_Short","filePath":"DM/short/Graph_Theory_Planarity_Short.md","title":"Graph_Theory_Planarity_Short","links":["tags/gate","tags/dm","tags/short","tags/graphs"],"tags":["gate","dm","short","graphs"],"content":"gate dm short graphs\nPlanarity (Short Notes)\nBasic Concepts\n\nPlanar Graph: Graph jo draw kiya ja sake bina edges cross kiye.\nBounded Region: Finite area enclosed by edges.\nUnbounded Region: Outer infinite area (Always 1).\nStandard Non-Planar Graphs:\n\nK5​: Smallest non-planar by vertices (n=5).\nK3,3​: Smallest non-planar by edges (e=9).\n\n\n\n\n\n                  \n                  NOTE\n                  \n                \n\nK5​ aur K3,3​ dono regular graphs hain. Dono non-planar hain par ek edge remove karne se planar ban jate hain.\n\n\n\nFormulas &amp; Theorems\n1. Euler’s Formula\nFor connected planar graph:\nn−e+f=2\nFor disconnected (k components):\nn−e+f=k+1\n2. Sum of Region Degrees\n∑d(Ri​)=2e\nHar edge 2 regions mein count hoti hai (ya same region mein 2 baar).\n3. Edge Inequalities (Necessary Conditions)\nAgar ye fail hui to graph Non-Planar hai.\n\nGeneral Graph:\ne≤3n−6\nTriangle-Free Graph (No 3-cycle):\ne≤2n−4\n(Example: Bipartite graphs, K3,3​).\n\n4. Minimum Degree\nPlanar graph mein minimum degree δ(G)≤5.\n(Always average degree &lt;6).\n\nRelevant PYQs\nGATE CSE 2014\nQ: 10 vertices, each face has 3 edges. Find e.\nSol:\n3f=2e⟹f=2e/3.\n10−e+2e/3=2⟹e=24.\nKuratowski’s Theorem\nA graph is non-planar if and only if it contains a subgraph homeomorphic to K5​ or K3,3​."},"DM/short/Predicate_Logic_Basics_Short":{"slug":"DM/short/Predicate_Logic_Basics_Short","filePath":"DM/short/Predicate_Logic_Basics_Short.md","title":"Predicate_Logic_Basics_Short","links":["tags/gate","tags/dm","tags/short","tags/logic","tags/predicate_logic"],"tags":["gate","dm","short","logic","predicate_logic"],"content":"gate dm short logic predicate_logic\nPredicate Logic (Revision)\nTopic: DM\nSubtopic: Predicate Logic\n\nKey Concepts\n\nP(x): Open Statement (Logic depend on x).\nUniverse/Domain (D): Set of all values x can take.\n\nQuantifiers\n\n\nUniversal (∀) - “For All”\n\nTrue iff P(x) is True for every x∈D.\nLike a big AND: P(1)∧P(2)∧…\nTo prove False: Find 1 counterexample.\n\n\n\nExistential (∃) - “There Exists”\n\nTrue iff P(x) is True for at least one x∈D.\nLike a big OR: P(1)∨P(2)∨…\nTo prove False: Show it is never true.\n\n\n\nRules of Distribution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatementEquivalent Split?StatusNote∀x(P(x)∧Q(x))∀xP(x)∧∀xQ(x)Valid∀ distributes over ∧∀x(P(x)∨Q(x))∀xP(x)∨∀xQ(x)InvalidLHS can be mixed, RHS needs all P or all Q∃x(P(x)∨Q(x))∃xP(x)∨∃xQ(x)Valid∃ distributes over ∨∃x(P(x)∧Q(x))∃xP(x)∧∃xQ(x)InvalidLHS needs same x, RHS can have diff x\nImportant Implications (Valid Directions)\n\n∀xP(x)∨∀xQ(x)⟹∀x(P(x)∨Q(x))\n∃x(P(x)∧Q(x))⟹∃xP(x)∧∃xQ(x)\n\nNegation Rules (De Morgan’s for Logic)\n\n¬(∀xP(x))≡∃x(¬P(x))\n¬(∃xP(x))≡∀x(¬P(x))\n\nQuick Questions\n\nD={1,2,3}, ∀x(x2=4) → False (fails for 1)\nD=Z, ∃n(n2≤10) → True (e.g., n=1)\n¬[∀xP(x)] → ∃x¬P(x)\n"},"DM/short/Propositional_Logic_Short":{"slug":"DM/short/Propositional_Logic_Short","filePath":"DM/short/Propositional_Logic_Short.md","title":"Propositional_Logic_Short","links":["tags/gate","tags/dm","tags/short","tags/logic","tags/propositional_logic"],"tags":["gate","dm","short","logic","propositional_logic"],"content":"gate dm short logic propositional_logic\nPropositional Logic (Short Notes)\nDate: 03/02/2026\n\nQuick Concepts (Hinglish)\n1. Types of Statements\n\nSimple Statement: Jisko aur tod nahi sakte. Ex: “It is raining” (p).\nCompound Statement: Jisme connectives (AND, OR) use hote hain. Ex: “It is raining AND I am happy”.\n\n2. Connectives &amp; Truth Table Shortcuts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConnectiveSymbolHint (Hinglish)AND∧True tabhi hoga jab dono True honge. (Sab sahi hona chahiye).OR∨False tabhi hoga jab dono False honge. (Ek bhi sahi toh sab sahi).Implication→Only False case: T→F is FALSE. Baaki sab True. (Pehle wala sahi, doosra galat = Galat).Bi-Implication↔Agar dono ki value SAME hai (T↔T ya F↔F) toh True. Different hai toh False.\n\nDefinitions (Yaad rakho)\n\nSatisfiable: Jaldi se check karo ki kya kam se kam ek baar True aa raha hai? Agar haan, toh wo Satisfiable hai. (Tautology bhi satisfiable hoti hai).\nTautology (Valid): Agar SAARE cases (combinations) mein result True hai.\n\nTip: Prove karne ke liye ulta socho. Try karo expression ko False prove karne ki. Agar fail ho gaye (contradiction mili), toh wo Tautology hai.\n\n\nContradiction: Agar SAARE cases mein result False hai.\nContingency: Mixed result. Kabhi True, kabhi False.\n\n\nInference Rule Check\nPremise ko True maano, aur check karo ki Conclusion bhi True aa raha hai ya nahi.\nExample (Phone wala):\n\nP1​: Phone Left ya Right pocket mein hai (L∨R).\nP2​: Phone Left mein nahi hai (¬L).\nResult: Toh pakka Right mein hoga (R).\nYeh Valid hai. (Disjunctive Syllogism).\n\n\nImportant Rules\n\n\nModus Ponens: a→b aur a diya hai → toh b true hoga.\nModus Tollens: a→b aur ¬b diya hai → toh ¬a true hoga.\nHypothetical Syllogism: Chain rule. a→b aur b→c → toh a→c.\n\n"},"DM/short/Quantifiers_Logic":{"slug":"DM/short/Quantifiers_Logic","filePath":"DM/short/Quantifiers_Logic.md","title":"Quantifiers_Logic","links":["tags/gate","tags/dm","tags/short","tags/logic","tags/quantifiers","tags/nested_quantifiers"],"tags":["gate","dm","short","logic","quantifiers","nested_quantifiers"],"content":"Quantifiers &amp; Nested Logic (Short)\nDate: 10/02/2026\nTags: gate dm short logic quantifiers nested_quantifiers\n\nImportant Rules\n1. IMP Formulae (Implications vs Equivalences)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFormulaTypeLogic Check∀x(P(x)∧Q(x))≡All P AND All Q (Valid both ways)∃x(P(x)∨Q(x))≡Exists P OR Exists Q (Valid both ways)∃x(P(x)∧Q(x))→Only implies ∃xP∧∃xQ. (LHS is stronger)∀x(P(x)∨Q(x))←Implied by (∀xP)∨(∀xQ). (RHS is stronger)\nSummary:\n\n∀ works perfectly with ∧ (AND).\n∃ works perfectly with ∨ (OR).\nBe careful with mixed pairs! (∃ with ∧ implies specific instance, ∀ with ∨ implies weaker generality).\n\n2. Nested Quantifiers Hierarchy (The Diagram)\nRemember this chain for solving equivalences quickly:\n∀x∀y→∃y∀x→∀x∃y→∃x∃y\n\nLeft to Right always TRUE.\nRight to Left generally FALSE.\n\nMeaning in simple words:\n\n∃y∀x: One Global Key (y) opens All Locks (x).\n\nExample: A mother (y) loves all her children (x).\n\n\n∀x∃y: Every Lock (x) has Some Key (y).\n\nExample: Every child (x) has a mother (y). (But not necessarily the same mother for everyone in the world).\n\n\n\nTherefore: If there is one mother for all (1), then implies every child has a mother (2). True.\nBut if every child has a mother (2), does implies valid one mother for all (1)? False.\n3. Quick Tips for Questions\n\nCheck Domain (D): Empty domain can break rules, usually assume non-empty.\nOrder Matters: ∀∃=∃∀.\nNegation: Flip quantifier and negate inner predicate.\n\n¬(∀x∃yP)≡∃x∀y(¬P).\n\n\n\n4. Cheat Sheet Formulas\n\nP→Q≡¬P∨Q\n∀x(P→Q)≡∀x(¬P∨Q)\n∀xP→∀xQ is weaker than ∀x(P→Q).\n"},"DM/short/Set_Theory_Relations_Short":{"slug":"DM/short/Set_Theory_Relations_Short","filePath":"DM/short/Set_Theory_Relations_Short.md","title":"Set_Theory_Relations_Short","links":["DM/long/Set_Theory_Relations"],"tags":["gate","dm","relations","short"],"content":"Set Theory - Relations (Short Notes)\nLong Notes\nBasics\nRelation: Subset of A×B.\nTotal Relations from A to B (∣A∣=m,∣B∣=n): 2mn\nTotal Relations on A (∣A∣=n): 2n2\n\nTypes of Relations &amp; Counting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTypeDefinitionCounting FormulaReflexive∀a,(a,a)∈R2n2−nSymmetric(a,b)∈R⟹(b,a)∈R22n(n+1)​Anti-Symmetric(a,b)∈R∧(b,a)∈R⟹a=b2n⋅32n(n−1)​Asymmetric(a,b)∈R⟹(b,a)∈/R32n(n−1)​Reflexive &amp; SymmetricBoth22n(n−1)​\n\nKey Points (Hinglish)\n\nReflexive: Sab elements ka khud se relation hona chahiye (diagonal elements must be present). E.g., (1,1),(2,2),(3,3).\nSymmetric: Agar ek pair hai (a,b), toh uska ulta (b,a) bhi hona chahiye. Check karne ke liye pair ko flip karo, agar set same rahe toh symmetric hai.\nAnti-Symmetric: Agar (a,b) aur (b,a) dono hain, toh a=b hona chahiye. Basically, a=b ke liye sirf ek direction allow hai ya koi nahi. Dono direction allow nahi hain except diagonal.\nOperations:\n\nUnion/Intersection of Symmetric is also Symmetric.\nUnion/Intersection of Reflexive is also Reflexive.\nIntersection of Anti-Symmetric is Anti-Symmetric (Union is NOT guaranteed).\n\n\n\n\nImportant Formulas Derivation Logic\n\nReflexive: Diagonal fixed (1 choice). Remaining n2−n pairs independent (2 choices).\nSymmetric: Diagonal independent (2 choices). Upper triangle (2n2−n​) entries independent. Lower triangle fixed based on upper. Total n+2n2−n​=2n(n+1)​ independent choices.\nAnti-Symmetric: Diagonal independent (2 choices). Each off-diagonal pair {(a,b),(b,a)} has 3 choices: only (a,b), only (b,a), or neither. Total 2n⋅32n(n−1)​.\n"},"DSA/data-structures-and-algorithm":{"slug":"DSA/data-structures-and-algorithm","filePath":"DSA/data structures and algorithm.md","title":"data structures and algorithm","links":["tags/PROGRAMMING","tags/PLACEMENTS","tags/queue"],"tags":["PROGRAMMING","PLACEMENTS","queue"],"content":"\nSyllabus of Data Structures and Algorithms | DSA for GATE | GATE 2023\n\n\nIntroduction to data structures and algorithms | DSA | Part 1 | GATE 2023\n\n\nIntroduction to data structures and algorithms | DSA | Part 2 | GATE 2023\n\n\nHow to analyze algorithm | Aposteriori analysis | analysis of algorithm\n\n\nHow to analyze algorithm | Apriori analysis | analysis of algorithm\n\n\nHow to analyze algorithm | Asymptotic Notations (part 1) | analysis of algorithm\n\n\nHow to analyze algorithm | Asymptotic Notations (part 2) | Big O notation | analysis of algorithm\n\n\nHow to analyze algorithm | Asymptotic Notations (part 3) | Big O notation | analysis of algorithm\n\n\nHow to analyze algorithm | Asymptotic Notations (part 4) | Big O notation | analysis of algorithm\n\n\nHow to analyze algorithm | Asymptotic Notations (part 5) | Big omega notation |analysis of algorithm\n\n\nHow to analyze algorithm | Asymptotic Notations (part 6) | Theta notation | analysis of algorithm\n\n\nHow to analyze algorithm | Asymptotic Notations (part 7) | small o and  small omega (ω) notation\n\n\nHow to analyze algorithm | Properties of Asymptotic Notations (part 1)\n\n\nHow to analyze algorithm | Properties of Asymptotic Notations (part 2)\n\n\nHow to analyze algorithm | Properties of Asymptotic Notations (part 3)\n\n\nHow to Analyze Algorithm | Practice Questions on Asymptotic Notations | Analysis of Algorithm\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #2\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #3\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #4\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #5\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #6\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #7\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #8\n\n\nHow to Analyze Algorithm | Analysis of Algorithm  Practice Questions on Asymptotic Notations  #9\n\n\nFinding Time Complexity | Analysis and Calculation | Time Complexity of iterative Algo | part 1\n\n\nFinding Time Complexity | Analysis and Calculation | Time Complexity of iterative Algo | part 2\n\n\nFinding Time Complexity | Analysis and Calculation | Time Complexity of iterative Algo | part 3\n\n\nFinding Time Complexity | Analysis and Calculation | Time Complexity of iterative Algo | part 4\n\n\nFinding Time Complexity | Analysis and Calculation | Time Complexity of iterative Algo | part 5\n\n\nFinding Time Complexity | Analysis and Calculation | Time Complexity of iterative Algo | part 6\n\n\nFinding Time Complexity | Analysis and Calculation | Time Complexity of iterative Algo | part 7\n\n\nFinding Space Complexity | Analysis and Calculation | Iterative Algorithms\n\n\nFinding Space and Time Complexity of Recursive Algorithms | Analysis and Calculation | Part 1\n\n\nFinding Space and Time Complexity of Recursive Algorithms | Analysis and Calculation | Part 2\n\n\nFinding Space and Time Complexity of Recursive Algorithms | Analysis and Calculation | Part 3\n\n\nFinding Space and Time Complexity of Recursive Algorithms | Analysis and Calculation | Part 4\n\n\nFinding Space and Time Complexity of Recursive Algorithms | Analysis and Calculation | Part 5\n\n\nFinding Space and Time Complexity of Recursive Algorithms | Analysis and Calculation | Part 6\n\n\nFinding Space and Time Complexity of Recursive Algorithms | fibonacci series exact complexity |#7\n\n\nTower of Hanoi solved using Recursion | Part 1\n\n\nTower of Hanoi solved using Recursion | Part 2\n\n\nSUBSTITUTION METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 1\n\n\nSUBSTITUTION METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 2\n\n\nSUBSTITUTION METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 3\n\n\nSUBSTITUTION METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 4\n\n\nSUBSTITUTION METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 5\n\n\nTREE  METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 1\n\n\nTREE  METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 2\n\n\nTREE  METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 3\n\n\nTREE  METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 4\n\n\nTREE  METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 5\n\n\nTREE  METHOD FOR SOLVING ANY RECURRENCE IN HINDI | part 6\n\n\nMaster Theorem with Proof part 1\n\n\nMaster Theorem with Proof part 2\n\n\nMaster Theorem with Proof part 3\n\n\nMaster Theorem with Proof part 4\n\n\nMaster Theorem with Proof part 5\n\n\nPractice Questions on Master Theorem Part 1\n\n\nPractice Questions on Master Theorem Part 2\n\n\nPractice Questions on Master Theorem Part 3\n\n\nPractice Questions on Master Theorem Part 4\n\n\nAdvanced Master Theorem | Extended Master Theorem with intuitive proof\n\n\nLinear Search part 1\n\n\nLinear Search part 2\n\n\nLinear Search part 3\n\n\nBinary Search part 1\n\n\nBinary Search part 2\n\n\nBinary Search part 3 (Modified Binary Search)\n\n\nBinary Search part 4 (Average case exact number of comparisons)\n\n\nBinary Search part 5 (Average case analysis of Binary search)\n\n\nBinary Search part 6 (Practice Questions)\n\n\nBinary Search part 7 (Practice Questions) PROGRAMMING PLACEMENTS\n\n\nBinary Search part 8 (Practice Questions) PROGRAMMING PLACEMENTS\n\n\nBinary Search part 9 (Practice Questions) PROGRAMMING PLACEMENTS\n\n\nBinary Search part 10 (Practice Questions) PROGRAMMING PLACEMENTS\n\n\nSelection Sort | Time Complexity(Best, Avg &amp; Worst) Analysis PROGRAMMING PLACEMENTS\n\n\nSelection Sort | Stable or Not | In Place or Not | Practice Questions PROGRAMMING PLACEMENTS\n\n\nBubble Sort Part 1 | Performance of Bubble Sort | Algorithm PROGRAMMING PLACEMENTS\n\n\nBubble Sort Part 2 | Performance of Bubble Sort | Algorithm PROGRAMMING PLACEMENTS\n\n\nInsertion Sort | Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nInsertion Sort (part 2)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nCounting Sort (part 1)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nCounting Sort (part 2)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nRadix Sort (part 1)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nRadix Sort (part 2)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nInsertion Sort (part 3)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 1)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 2)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 3)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 4)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 5)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 6)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 7)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 8)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 9)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 10)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 11)| Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nHeap Sort (part 12) Time Complexity Analysis | Algorithm PROGRAMMING PLACEMENTS\n\n\nARRAY IN DATA STRUCTURES PART 1\n\n\nARRAY IN DATA STRUCTURES PART 2\n\n\nARRAY IN DATA STRUCTURES PART 3\n\n\nARRAY IN DATA STRUCTURES PART 4\n\n\nIntroduction to Linked List Part 1\n\n\nIntroduction to Linked List Part 2\n\n\nIntroduction to Linked List Part 3\n\n\nIntroduction to Linked List Part 4\n\n\nIntroduction to Linked List Part 5\n\n\nIntroduction to Linked List Part 6\n\n\nIntroduction to Linked List Part 7\n\n\nIntroduction to Linked List Part 8\n\n\nIntroduction to Linked List Part 9\n\n\nIntroduction to Linked List Part 10\n\n\nIntroduction to Linked List Part 11\n\n\nIntroduction to Linked List Part 12\n\n\nIntroduction to Linked List Part 13\n\n\nIntroduction to Linked List Part 14\n\n\nTree in Data Structure (Part 1)| Introduction to Trees | Data Structures Tutorials\n\n\nTree in Data Structure (Part 2)| Introduction to Trees | Data Structures Tutorials\n\n\nTree in Data Structure (Part 3)| Introduction to Trees | Data Structures Tutorials\n\n\nTree in Data Structure (Part 4)| Introduction to Trees | Data Structures Tutorials\n\n\nTree in Data Structure (Part 5)| Introduction to Trees | Data Structures Tutorials\n\n\nTree in Data Structure (Part 6)| Introduction to Trees | Data Structures Tutorials\n\n\nBinary Search Tree in Data Structure (Part 1)| Introduction to Trees | Data Structures Tutorials\n\n\nBinary Search Tree in Data Structure (Part 2)| Introduction to Trees | Data Structures Tutorials\n\n\nBinary Search Tree in Data Structure (Part 3)| Introduction to Trees | Data Structures Tutorials\n\n\nBinary Search Tree in Data Structure (Part 4)| Introduction to Trees | Data Structures Tutorials\n\n\nBinary Search Tree in Data Structure (Part 5)| Introduction to Trees | Data Structures Tutorials\n\n\nTree Traversal in Data Structure (Part 1)| Introduction to Trees | Data Structures Tutorials\n\n\nTree Traversal in Data Structure (Part 2)| Introduction to Trees | Data Structures Tutorials\n\n\nTree Traversal in Data Structure (Part 3)| Introduction to Trees | Data Structures Tutorials\n\n\nTree Traversal in Data Structure (Part 4)| Introduction to Trees | Data Structures Tutorials\n\n\nTree Traversal in Data Structure (Part 5)| Introduction to Trees | Data Structures Tutorials\n\n\nGATE 2014 question on IN Order traversal | Introduction to Trees | Data Structures Tutorials\n\n\nGATE 2014 question on Leftmost child Right Sibling| Introduction to Trees| Data Structures Tutorials\n\n\nCounting Trees in Data Structure (Part 1)| Introduction to Trees | Data Structures Tutorials\n\n\nCounting Trees in Data Structure (Part 2)| Introduction to Trees | Data Structures Tutorials\n\n\nMost important PYQ of TREE | Tree in Data Structure|Introduction to Trees| Data Structures Tutorials\n\n\nAVL Trees in Data Structure (Part 1)| Introduction to Trees | Data Structures Tutorials\n\n\nAVL Trees in Data Structure (Part 2)| Introduction to Trees | Data Structures Tutorials\n\n\nAVL Trees in Data Structure (Part 3)| Introduction to Trees | Data Structures Tutorials\n\n\nAVL Trees in Data Structure (Part 4)| Introduction to Trees | Data Structures Tutorials\n\n\nAVL Trees in Data Structure (Part 5)| Introduction to Trees | Data Structures Tutorials\n\n\nAVL Trees in Data Structure (Part 6)| Introduction to Trees | Data Structures Tutorials\n\n\nGATE 2014 question on Sub Trees | Introduction to Trees | Data Structures Tutorials\n\n\nExpression Trees in Data Structure| Introduction to Trees | Data Structures Tutorials\n\n\nVarious representation of Trees| Introduction to Trees | Data Structures Tutorials\n\n\nGraph Representation in Data Structure |Adjacency Matrix and Adjacency List(part 1)\n\n\nGraph Representation in Data Structure |Adjacency Matrix and Adjacency List(part 2) | Universal Sink\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search | Graph Traversing | DAA | Part 1\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search | Graph Traversing | DAA | Part 2\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search | Graph Traversing | DAA | Part 3\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search | Graph Traversing | DAA | Part 4\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search | Graph Traversing | DAA | Part 5\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search | Graph Traversing | DAA | Part 6\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search (Iterative)| Graph Traversing | DAA | Part 7\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search (Iterative)| Graph Traversing | DAA | Part 8\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search (Iterative)| Graph Traversing | DAA | Part 9\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search Discover time and Finish Time | DAA | Part 10\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search Types of Edges | DAA | Part 11\n\n\nBFS &amp; DFS | Breadth First Search | Depth First Search Types of Edges | DAA | Part 12\n\n\nBFS &amp; DFS | Breadth First Search | Breadth First Search Types of Edges | DAA | Part 13\n\n\nParameter Passing Techniques | Call by value | Call by Reference | Part 1\n\n\nParameter Passing Techniques | Call by value | Call by Reference | Part 2\n\n\nIntroduction To Stacks part 1 | GATE 2025\n\n\nIntroduction To Stacks part 2 | GATE 2025\n\n\nIntroduction To Stacks part 3 | GATE 2025\n\n\nIntroduction To Stacks part 4 | GATE 2025\n\n\nIntroduction To Stacks part 5 | PYQs on Stack | GATE 2025\n\n\nIntroduction To Stacks part 6 |  Implementing Stack Using LLst| GATE 2025\n\n\nIntroduction to Queue Data structure | Part 1| Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 2| Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 3| Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 4| Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 5| Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 6| Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 7| Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 8 | Data Structure queue | GATE 2006 question\n\n\nIntroduction to Queue Data structure | Part 9 | Data Structure queue | GATE 2022 question\n\n\nIntroduction to Queue Data structure | Part 10 | Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 11 | Data Structure queue | GATE 2025\n\n\nIntroduction to Queue Data structure | Part 12 | Data Structure queue | GATE 2025\n"},"Digital/Media-Note---Conversions-in-number-system-(base-10-to-base-x)_-Number-system-in-Digital-Logic-_-GATE-2023":{"slug":"Digital/Media-Note---Conversions-in-number-system-(base-10-to-base-x)_-Number-system-in-Digital-Logic-_-GATE-2023","filePath":"Digital/Media Note - Conversions in number system (base 10 to base x)_ Number system in Digital Logic _ GATE 2023.md","title":"Media Note - Conversions in number system (base 10 to base x)_ Number system in Digital Logic _ GATE 2023","links":[],"tags":[],"content":"\n00:49\n 01:39\nfor conversion, divide the number by the base till 0 and then write in reverse order,\nfor decimals, keep multiplying\n"},"Digital/Media-Note---Conversions-in-number-system-(base-x-to-base-10)_-Number-system-in-Digital-Logic-_-GATE-2023":{"slug":"Digital/Media-Note---Conversions-in-number-system-(base-x-to-base-10)_-Number-system-in-Digital-Logic-_-GATE-2023","filePath":"Digital/Media Note - Conversions in number system (base x to base 10)_ Number system in Digital Logic _ GATE 2023.md","title":"Media Note - Conversions in number system (base x to base 10)_ Number system in Digital Logic _ GATE 2023","links":[],"tags":[],"content":"\n00:01\n\n"},"Digital/Media-Note---Introduction-to-number-system-_-Number-system-in-Digital-Logic-_-GATE-2023":{"slug":"Digital/Media-Note---Introduction-to-number-system-_-Number-system-in-Digital-Logic-_-GATE-2023","filePath":"Digital/Media Note - Introduction to number system _ Number system in Digital Logic _ GATE 2023.md","title":"Media Note - Introduction to number system _ Number system in Digital Logic _ GATE 2023","links":[],"tags":[],"content":"\n26:12  Base cannot be greater than the largest number\nso for 888.84, base will be &gt;= 9\n46:50 \n"},"Digital/digital-logic":{"slug":"Digital/digital-logic","filePath":"Digital/digital logic.md","title":"digital logic","links":[],"tags":[],"content":"\nIntroduction to number system | Number system in Digital Logic | GATE 2023\n\n\nSyllabus of Digital Logic | Digital Logic | GATE 2023\n\n\nConversions in number system (base 10 to base x)| Number system in Digital Logic | GATE 2023\n\n\nConversions in number system (base x to base 10)| Number system in Digital Logic | GATE 2023\n -------\n\nConversions in number system (base x to base y)| Number system in Digital Logic | GATE 2023\n\n\nPractice questions on Conversions in number system| Number system in Digital Logic | GATE 2023\n\n\nTricks for Conversions in number system| Number system in Digital Logic | GATE 2023\n\n\nPractice questions on number system| Number system in Digital Logic | GATE 2023\n\n\nAddition in different bases (computer number system) | octal addition | hexadecimal addition\n\n\nSubtraction in different bases (number system) | octal Subtraction | hexadecimal subtraction\n\n\nMultiplication and Division in different bases | octal multiplication | octal Division\n\n\ncompliments in base r | r’s Complement | (r-1)‘s Complement\n\n\nSubtraction using r’s Complement Method - Number System - Digital Circuits GATE\n\n\nSubtraction using (r-1)‘s Complement Method - Number System - Digital Circuits GATE\n\n\nBinary Coded Decimal (BCD) Code | BCD Addition | GATE 2023\n\n\nBinary Coded Decimal (BCD) Code | BCD Subtraction | GATE 2023\n\n\nExcess-3 Code (X-3 Code) | GATE 2023\n\n\nSELF COMPLIMENTING CODES| EXCESS 3 CODE | 2421 CODE | GATE 2023\n\n\nIntroduction to Gray Code | binary to gray | gray to binary | GATE 2023\n\n\nAlphanumeric codes | ASCII | EBCDIC | UNICODE | GATE 2023\n\n\nRepresentation of integers in computers | SMR | 1’s and 2’s compliment representation\n\n\nRepresentation of NEGATIVE integers in computers | 1’s compliment representation | GATE 2023\n\n\nRepresentation of NEGATIVE integers in computers | signed magnitude representation | SMR | GATE 2023\n\n\nRepresentation of NEGATIVE integers in computers | 2’s compliment representation | GATE 2023\n\n\nfixed point notation | fixed point representation | GATE 2023\n\n\nFloating point representation | Floating point notation | Part 1\n\n\nFloating Point Representation: IEEE - 754 Representation| part 1 | single precision\n\n\nFloating Point Representation: IEEE - 754 Representation | part 2 | Double precision\n\n\nFloating point representation | Floating point notation | Part 2\n\n\nFloating point representation | Floating point notation | Part 3\n\n\nFloating Point Representation: IEEE-754 Representation | part3 | special numbers in Single precision\n\n\nFloating Point Representation: IEEE-754 | part 4 | smallest and largest numbers in Single precision\n\n\nFloating Point Representation: IEEE-754 | part 5 | gap between numbers in Single precision\n\n\nFloating Point Representation: IEEE-754 | part 6 | smallest and largest numbers in double precision\n\n\nFloating Point Representation: IEEE - 754 Representation| part 7 | GATE questions single precision\n\n\nBoolean algebra introduction | GATE 2023\n\n\nBoolean Laws in Digital logic | GATE 2023 | Part 1\n\n\nBoolean Laws in Digital logic | GATE 2023 | Part 2\n\n\nTypes of Logic Gates | Symbols | Truth Tables | part 1(basic gates)\n\n\nTypes of Logic Gates | Symbols | Truth Tables | part 2(Derived gates)\n\n\nUniversal GATES | NAND as Universal Gate | NOR as Universal Gate\n\n\nPrinciple of duality  | Dual of a Boolean function | Duality theorem | Properties of duality | part1\n\n\nPrinciple of duality  | Dual of a Boolean function | Duality theorem | Properties of duality | part2\n\n\nSum of Products | SOP Form\n\n\nProduct of Sums | POS Form | GATE 2023\n\n\nSOP TO POS FORM CONVERSION | GATE 2023\n\n\nPOS TO SOP FORM CONVERSION | GATE 2023\n\n\nself dual and neutral functions | Number of Self Dual and neutral Functions | GATE 2023\n\n\northogonal functions in digital logic | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 2 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 3 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 1 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 4 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 5 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 6 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 7 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 8 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 9 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 10 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 11 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 12 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 13 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 14 | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 15 | GATE 2023\n\n\nUnderstanding Variable Entrant Map | VEM | GATE 2023\n\n\nK-Map | Design K-Map | KARNAUGH MAP | PART 16 | GATE 2023\n\n\nHalf Adder | Combinational Circuits |Digital Electronics | GATE 2023\n\n\nINTRODUCTION  TO COMBINATORIAL CIRCUITS | DESIGNING COMBINATORIAL CIRCUITS | GATE 2023\n\n\nFull Adder | Part 1| Combinational Circuit | Digital Electronics | GATE 2023\n\n\nFull Adder | Part 2| Combinational Circuit | Digital Electronics | GATE 2023 | Part 2\n\n\nBCD Adder | Simple Explanation\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 1) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 3) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 2) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 4) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 5) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 6) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 5 correction) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 7) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 8) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 9) | CLA Generator\n\n\nLook Ahead Carry Adder | Carry Look ahead Adder (Part 10) | CLA Generator\n\n\nHalf Subtractor | Combinational Circuits |Digital Electronics | GATE 2023\n\n\nFull Subtractor|  Part 1| Combinational Circuits |Digital Electronics | GATE 2023\n\n\nFull Subtractor | part 2| Combinational Circuits |Digital Electronics | GATE 2023\n\n\n4-bit Adder and Subtractor Circuit\n\n\nHalf Subtractor using NAND / NOR Gates | Full Subtractor using NAND/NOR Gates\n\n\nHalf Adder using NAND / NOR Gates | Full Adder using NAND/NOR Gates\n\n\nHow to find Minimum Number of NAND/NOR GATES? | Digital Circuits PART 3\n\n\nHow to find Minimum Number of NAND/NOR GATES? | Digital Circuits\n\n\nHow to find Minimum Number of NAND/NOR GATES? | Digital Circuits PART 2\n\n\nHow to find Minimum Number of NAND/NOR GATES? | Digital Circuits PART 4\n\n\nHow to find Minimum Number of NAND/NOR GATES? | Digital Circuits PART 5\n\n\nHow to find Minimum Number of NAND/NOR GATES? | Digital Circuits PART 6\n\n\nHow to find Minimum Number of NAND/NOR GATES? | Digital Circuits PART 7\n\n\nWhat is a functional completeness? | Functionally Complete Set or Boolean Function | part 2\n\n\nWhat is a functional completeness? | Functionally Complete Set or Boolean Function | part 1\n\n\nWhat is a functional completeness? | Functionally Complete Set or Boolean Function | part 3\n\n\nWhat is a functional completeness? | Functionally Complete Set or Boolean Function | part 4\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics | part 2\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics | part 3\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics | part 4\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics | part 5\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics | part 6\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics | part 7\n\n\nIntroduction to Multiplexer | What are Multiplexers | Digital Electronics | part 8\n\n\nIntroduction to Demultiplexers | What are Demultiplexers | Digital Electronics\n\n\nIntroduction to Demultiplexers | What are Demultiplexers | Digital Electronics | part 2\n\n\nDecoder Part 1 | GATE 2023\n\n\nDecoder Part 2 | GATE 2023\n\n\nDecoder Part 3 | GATE 2023\n\n\nDecoder Part 4 | GATE 2023\n\n\nEncoder in Digital Electronics | Working, Application and Logic Circuit of Encoder | Part 1\n\n\nEncoder in Digital Electronics|Working,Application and Logic Circuit of Encoder|#2|Priority encoder\n\n\nEncoder in Digital Electronics | Working, Application and Logic Circuit of Encoder | Part 3\n\n\nWhat is Magnitude Comparator (Digital Comparator) | 1-bit, 2-bit and 3-bit Comparators Explained\n\n\nROM - Read Only Memory (Basics, Structure and size), Digital Electronics\n\n\nROM - Read Only Memory (Basics, Structure and size), Digital Electronics | PART 2\n\n\nROM - Read Only Memory (Basics, Structure and size), Digital Electronics | PART 3\n\n\nROM - Read Only Memory (Basics, Structure and size), Digital Electronics | PART 4\n\n\nROM - Read Only Memory (Basics, Structure and size), Digital Electronics | PART 5\n\n\nIntroduction to Sequential Circuits\n\n\n1 Bit Memory Cell | Latch | Cross Coupled NOT Gates\n\n\nSR Latch | NOR SR latch\n\n\nSR Latch | NAND SR latch | Race Condition\n\n\nGated SR latch | SR Latch\n\n\nSR Latch Truth Table , Excitation Table, State Diagram\n\n\nSR Latch Timing Diagram or waveform , Characteristic Equation\n\n\nIntroduction to D Latch | Circuit, Working, Truth Table, Characteristic Equation &amp; Excitation Table\n\n\nConcept of Clock | Clocked SR Latch | SR Flip Flop\n\n\nConcept of Triggering | Level Trigger vs Edge Trigger Flip Flop\n\n\nJK Flip Flop | Part 1\n\n\nJK Flip Flop | Part 2\n\n\nJK Flip Flop | Part 3 | Race Around Condition\n\n\nMaster Slave JK Flip Flop | Digital Electronics\n\n\nIntroduction to T Flip Flop | Circuit, Working, Truth Table, Characteristics &amp; Excitation Table\n\n\nPreset &amp; Clear Inputs in Flip flop | Asynchronous Inputs\n\n\nPreset &amp; Clear Inputs in Flip flop | Asynchronous Inputs | Part 2\n\n\nFlip Flop Conversion | Sequential circuits | DIGITAL ELECTRONICS | Part 1\n\n\nFlip Flop Conversion | Sequential circuits | DIGITAL ELECTRONICS | Part 2\n\n\nFlip Flop Conversion | Sequential circuits | DIGITAL ELECTRONICS | Part 3\n\n\nFlip Flop Conversion | Sequential circuits | DIGITAL ELECTRONICS | Part 4\n\n\nIntroduction to Counters | Digital Electronics\n\n\nDesign Synchronous Counter | How to design Synchronous Counter | Digital Electronics | Part 1\n\n\nDesign Synchronous Counter | How to design Synchronous Counter | Digital Electronics | Part 2\n\n\nDesign Synchronous Counter | How to design Synchronous Counter | Digital Electronics | Part 3\n\n\nDesign Synchronous Counter | How to design Synchronous Counter | Digital Electronics | Part 4\n\n\nDesign Synchronous Counter | How to design Synchronous Counter | Digital Electronics | Part 5\n\n\nAsynchronous Counter or Ripple Counter | Part 1\n\n\nAsynchronous Counter or Ripple Counter | Part 2\n\n\nAsynchronous Counter or Ripple Counter | Part 3\n\n\nAsynchronous Counter or Ripple Counter | Part 4\n\n\nAsynchronous Counter or Ripple Counter | Part 5\n\n\nAsynchronous Counter or Ripple Counter | Part 6 | BCD counter\n\n\nAsynchronous Counter or Ripple Counter | Part 7 | BCD counter\n\n\nAsynchronous Counter or Ripple Counter | Part 8 | Finding MOD of counter\n\n\nAsynchronous Counter or Ripple Counter | Part 9 | Synchronous preset and clear\n\n\nAsynchronous Counter or Ripple Counter | Part 10 | Delay questions\n\n\nAsynchronous Counter or Ripple Counter | Part 11 | Frequency divisor\n\n\nSynchronous Counter as Frequency divisor\n\n\nSetup Time and Hold Time of Flip Flop Explained | Digital Electronics\n\n\nSetup Time and Hold Time of Flip Flop Explained | Digital Electronics | part 2\n\n\nAsynchronous Counter or Ripple Counter | Part 12 | up down counter\n\n\nShift Registers Part 1\n\n\nShift Registers Part 2\n\n\nShift Registers Part 3\n\n\nRing Counter | Synchronous Counters | Digital Electronics | Part 1\n\n\nRing Counter | Synchronous Counters | Digital Electronics | Part 2\n\n\nHow to make Ring Counter self starting | Synchronous Counters | Digital Electronics | Part 3\n\n\nTwisted Ring Counter | Johnson Counter | Synchronous Counters | Digital Electronics | Part 1\n\n\nTwisted Ring Counter | Johnson Counter | Synchronous Counters | Digital Electronics | Part 2\n\n\nTwisted Ring Counter | Johnson Counter | Synchronous Counters | Digital Electronics | Part 3\n\n\nShift Registers | SISO | SIPO | PIPO | PISO | Part 1\n\n\nShift Registers | SISO | SIPO | PIPO | PISO | Part 2\n\n\nDigital is Completed What next? | GATE 2024\n"},"Excalidraw/Drawing-2024-06-16-18.28.06.excalidraw":{"slug":"Excalidraw/Drawing-2024-06-16-18.28.06.excalidraw","filePath":"Excalidraw/Drawing 2024-06-16 18.28.06.excalidraw.md","title":"Drawing 2024-06-16 18.28.06.excalidraw","links":[],"tags":["excalidraw"],"content":"⚠  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠"},"Excalidraw/Drawing-2024-12-18-14.07.24.excalidraw":{"slug":"Excalidraw/Drawing-2024-12-18-14.07.24.excalidraw","filePath":"Excalidraw/Drawing 2024-12-18 14.07.24.excalidraw.md","title":"Drawing 2024-12-18 14.07.24.excalidraw","links":[],"tags":["excalidraw"],"content":"⚠  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠\nText Elements"},"Media-Note---15.-introduction-to-signals":{"slug":"Media-Note---15.-introduction-to-signals","filePath":"Media Note - 15. introduction to signals.md","title":"Media Note - 15. introduction to signals","links":[],"tags":[],"content":"\n 00:47\n"},"Media-Note---NIR-BHAU-Series-Lecture-1-_-Operating-System-_-CPU-Scheduling-_-Part-1-_-GATE-2023":{"slug":"Media-Note---NIR-BHAU-Series-Lecture-1-_-Operating-System-_-CPU-Scheduling-_-Part-1-_-GATE-2023","filePath":"Media Note - NIR BHAU Series Lecture 1 _ Operating System _ CPU Scheduling _ Part 1 _ GATE 2023.md","title":"Media Note - NIR BHAU Series Lecture 1 _ Operating System _ CPU Scheduling _ Part 1 _ GATE 2023","links":[],"tags":[],"content":"\n 13:20\n"},"Media-Note---youtube_-8RF4HnnPu-Y":{"slug":"Media-Note---youtube_-8RF4HnnPu-Y","filePath":"Media Note - youtube_ 8RF4HnnPu-Y.md","title":"Media Note - youtube_ 8RF4HnnPu-Y","links":[],"tags":[],"content":""},"OS/CPU-scheduling":{"slug":"OS/CPU-scheduling","filePath":"OS/CPU scheduling.md","title":"CPU scheduling","links":[],"tags":[],"content":"www.youtube.com/watch\nCPU scheduling is done by Short term scheduler\nDispatcher is used for context switching\n\ncontext switching is a overhead on the system"},"OS/FCFS":{"slug":"OS/FCFS","filePath":"OS/FCFS.md","title":"FCFS","links":[],"tags":[],"content":"First come first serve\nprocess id PID\nburst time BT\narrival time AT\nif arrival time is same, tiebreak is done by the shortest process id\nturn around time = PFT - PAT\npft = process finish time\npat = process arival time\nwaiting time = turn around time - burst time\n\nresponse time = process start time - process arrival time\nresponse time and waiting time will be same in non-premptive scheduling\nThroughout : number of process completed per unit of time\nso, 3 process completed in 30 units of time means throughput is 3/30\nCPU utilization : total burst time / completion time of all process\n(test question)\n"},"OS/Non-Premptive-scheduling":{"slug":"OS/Non-Premptive-scheduling","filePath":"OS/Non-Premptive scheduling.md","title":"Non-Premptive scheduling","links":["OS/FCFS","OS/SJF","LJF","HRRN"],"tags":[],"content":"resource cheen leta hai\ntypes of non premptive scheduling\n\nFCFS first come first serve\nSJF shortest job first\nLJF longest job first\nHRRN highest response ratio next\n"},"OS/OS":{"slug":"OS/OS","filePath":"OS/OS.md","title":"OS","links":["tags/SYSTEMS","tags/SOFTWARE"],"tags":["SYSTEMS","SOFTWARE"],"content":"\nNIR BHAU Series Lecture 1 | Operating System | CPU Scheduling | Part 1 | GATE 2023\n\n\nNIR BHAU Series Lecture 2 | Operating System | CPU Scheduling | Part 2 | FCFS | GATE 2023\n\n\nNIR BHAU Series Lecture 3 | Operating System | CPU Scheduling | Part 3 | FCFS | GATE 2023\n\n\nNIR BHAU Series Lecture 4 | Operating System | CPU Scheduling | Part 4 | SJF | GATE 2023\n\n\nNIR BHAU Series Lecture 5 | Operating System | CPU Scheduling | Part 5 | SRTF | GATE 2023\n\n\nNIR BHAU Series Lecture 6 | Operating System | CPU Scheduling | Part 6 | SRTF | GATE 2023\n\n\nNIR BHAU Series Lecture 7 | Operating System | CPU Scheduling | Part 7 | Round Robin | GATE 2023\n\n\nNIR BHAU Series Lecture 8 | Operating System | CPU Scheduling | Part 8 | Round Robin | GATE 2023\n\n\nNIR BHAU Series Lecture 9 | Operating System | CPU Scheduling | Part 9 | LJF | LRTF | GATE 2023\n\n\nNIR BHAU Series Lecture 10 | Operating System |  Priority Scheduling | Part 10 | HRRN | GATE 2023\n\n\nNIR BHAU Series Lecture 11| Operating System | 4 System calls related to process | fork | GATE 2023\n\n\nNIR BHAU Series Lecture 12 | Operating System | Introduction to Critical Section Problem\n\n\nNIR BHAU Series Lecture 13 | Operating System | Critical Section Problem | Mutual Exclusion\n\n\nNIR BHAU Series Lecture 14 | OS | Solution to Critical Section Problem (Software based) | Part 1\n\n\nNIR BHAU Series Lecture 15 | OS | Solution to Critical Section Problem (Software based) | Part 2\n\n\nNIR BHAU Series Lecture 16 | OS | Solution to Critical Section Problem | peterson solution | Part 3\n\n\nNIR BHAU Series Lecture 17 | OS | Solution to Critical Section Problem | Bakery algorithm | Part 4\n\n\nNIR BHAU Series Lecture 18 | OS | Solution to Critical Section Problem(h/w based) | test and set\n\n\nNIR BHAU Series Lecture 19 | OS | Solution to Critical Section Problem(h/w based) | swap function\n\n\nNIR BHAU Series Lecture 20 | OS | Solution to Critical Section Problem(h/w based) | correct solution\n\n\nNIR BHAU Series Lecture 21 | OS |Semaphores | Solution to Critical Section Problem(OS based)\n\n\nNIR BHAU Series Lecture 22 | OS |Semaphores | Solution to Critical Section Problem(OS based)\n\n\nNIR BHAU Series Lecture 23 | OS | Semaphores GATE questions | solution to Critical Section problem\n\n\nNIR BHAU Series Lecture 24 | OS | Semaphores GATE questions | solution to Critical Section problem\n\n\nNIR BHAU Series Lecture 25 | OS | Semaphores (Busy Waiting)| solution to Critical Section problem\n\n\nNIR BHAU Series Lecture 26 | OS | Semaphores | producer consumer problem | Critical Section problem\n\n\nNIR BHAU Series Lecture 27 | OS | Semaphores | GATE questions | Critical Section problem\n\n\nNIR BHAU Series Lecture 28 | OS | Semaphores |Reader writer problem | Critical Section problem\n\n\nNIR BHAU Series Lecture 29 | OS | Semaphores |Dining Philosopher problem | Critical Section problem\n\n\nNIR BHAU Series Lecture 30 | OS | Deadlock Avoidance Banker’s Algorithm with Example\n\n\nNIR BHAU Series Lecture 31 | OS | Deadlock Avoidance Banker’s Algorithm with Example part 2\n\n\nNIR BHAU Series Lecture 32 | OS | Deadlock Avoidance Banker’s Algorithm with Example part 3\n\n\nNIR BHAU Series Lecture 33 | OS | Deadlock Avoidance Banker’s Algorithm with Example part 4\n\n\nNIR BHAU Series Lecture 34 | OS | Introduction to paging part 1 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 35 | OS | Introduction to paging part 2 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 36 | OS | Introduction to paging part 3 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 37 | OS | Introduction to paging part 4 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 38 | OS | Multilevel paging part 1 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 39 | OS | Multilevel paging part 2 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 40 | OS | Multilevel paging part 3 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 41 | OS | Multilevel paging part 4 SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 42 | OS |  Segmentation | Segmentation Vs Paging SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 43 | Demand Paging part 1| Operating System   SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 44 | Demand Paging part 2| Operating System   SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 45 | Demand Paging part 3| Operating System   SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 46 | Demand Paging part 4 | Operating System   SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 47 | Demand Paging part 5 | Operating System   SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 48 | Disk Scheduling part 1 | Operating System   SYSTEMS SOFTWARE\n\n\nNIR BHAU Series Lecture 49 | Disk Scheduling part 2 | Operating System   SYSTEMS SOFTWARE\n\n\nFINALLY OS NIR BHAU SERIES COMPLETED!!!!\n"},"OS/Premptive-scheduling":{"slug":"OS/Premptive-scheduling","filePath":"OS/Premptive scheduling.md","title":"Premptive scheduling","links":["round-robin","OS/SRTF","LRTF","Multilevel-queue-scheduling","Multilevel-feedback-queue-scheduling"],"tags":[],"content":"resource cheen leta hai\ntypes of premptive scheduling\n\nround robin\nSRTF shortest remaining time first/next\n*LRTF longest remaining time first/next\nMultilevel queue scheduling\nMultilevel feedback queue scheduling\n"},"OS/SJF":{"slug":"OS/SJF","filePath":"OS/SJF.md","title":"SJF","links":[],"tags":[],"content":"Shortest Job First / Shortest Job Next\nIn SJF , Average waiting time is minimum.\nFCFS is tie breaker\nexample 1:\n\nexample 2:\n"},"OS/SRTF":{"slug":"OS/SRTF","filePath":"OS/SRTF.md","title":"SRTF","links":[],"tags":[],"content":"Shortest Remaining Time First\nwww.youtube.com/watch\njab jab new process aa raha ho, tab gantt chart me break laga kar shochu chota job konsa bacha hai.\n"},"Pasted-image-20240615100924.png":{"slug":"Pasted-image-20240615100924.png","filePath":"Pasted image 20240615100924.png.md","title":"Pasted image 20240615100924.png","links":[],"tags":[],"content":""},"README":{"slug":"README","filePath":"README.md","title":"README","links":[],"tags":[],"content":"Gate notes\ns"},"TOC/Finite-automata-and-regular-langauges":{"slug":"TOC/Finite-automata-and-regular-langauges","filePath":"TOC/Finite automata and regular langauges.md","title":"Finite automata and regular langauges","links":[],"tags":[],"content":""},"TOC/PDA-and-CFLs":{"slug":"TOC/PDA-and-CFLs","filePath":"TOC/PDA and CFLs.md","title":"PDA and CFLs","links":[],"tags":[],"content":""},"TOC/Terms-in-TOC":{"slug":"TOC/Terms-in-TOC","filePath":"TOC/Terms in TOC.md","title":"Terms in TOC","links":[],"tags":[],"content":""},"TOC/Turing-Machine-and-Undecidibility":{"slug":"TOC/Turing-Machine-and-Undecidibility","filePath":"TOC/Turing Machine and Undecidibility.md","title":"Turing Machine and Undecidibility","links":[],"tags":[],"content":""},"Tracker":{"slug":"Tracker","filePath":"Tracker.md","title":"Tracker","links":["DM/long/Graph_Theory_Basics","DM/short/Graph_Theory_Basics_Short","DM/long/Graph_Theory_Connectivity","DM/short/Graph_Theory_Connectivity_Short","DM/long/Graph_Theory_Adjacency_Matrix","DM/short/Graph_Theory_Adjacency_Matrix_Short","DM/long/Graph_Theory_Planarity","DM/short/Graph_Theory_Planarity_Short","DM/long/Propositional_Logic_Notes","DM/short/Propositional_Logic_Short","DM/long/Predicate_Logic_Basics_Long","DM/short/Predicate_Logic_Basics_Short","DM/long/Quantifiers_Logic","DM/short/Quantifiers_Logic","DM/long/Set_Theory_Relations","DM/short/Set_Theory_Relations_Short"],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntopicsubtopicdatelong note linkshort note linkyt linkDMGraph Theory Basics27/01/2026Graph_Theory_Basics.mdGraph_Theory_Basics_Short.mdLectureDiscrete MathGraph Theory - Connectivity29/01/2026LongShortLinkDMSpecial Types of Graphs29/01/2026Graph_Theory_Basics.mdGraph_Theory_Basics_Short.mdLectureDMGraph Theory - Adjacency Matrix31/01/2026Graph_Theory_Adjacency_Matrix.mdGraph_Theory_Adjacency_Matrix_Short.mdLectureDMGraph Theory - Planarity02/02/2026Graph_Theory_Planarity.mdGraph_Theory_Planarity_Short.mdLectureDMPropositional Logic03/02/2026Propositional_Logic_Notes.mdPropositional_Logic_Short.mdLectureDMPredicate Logic06/02/2026Predicate_Logic_Basics_Long.mdPredicate_Logic_Basics_Short.mdLectureDMQuantifiers &amp; Nested Logic10/02/2026Quantifiers_Logic.mdQuantifiers_Logic.mdLectureDMSet Theory - Relations12/02/2026Set_Theory_Relations.mdSet_Theory_Relations_Short.mdLecture"},"index":{"slug":"index","filePath":"index.md","title":"GATE 2027 Notes","links":["CN/","OS/OS","DM/","TOC/","DBMS/DBMS","DSA/","Digital/","CLANG/","Tracker"],"tags":[],"content":"Welcome to GATE 2027 Notes\nHere are the notes for various subjects:\n\nComputer Networks\nOperating Systems\nDiscrete Mathematics\nTheory of Computation\nDatabase Management Systems\nData Structures &amp; Algorithms\nDigital Logic\nC Programming\n\nOther\n\nTracker\n"},"s":{"slug":"s","filePath":"s.md","title":"s","links":[],"tags":[],"content":"www.youtube.com/watch\nBiryani masala\ncoriander seeds 2 tbsp\njeera 1tsp\nshah jeet 2tsp\ngreen cardamom 2tbsp\nblack cardamom (moti elaichi) 5-6\ncinamon 3 inch\nkali miri 1tbsp\nred chili 7-8\ntej patta 7-8\ncloves 2tsp\nmace (javitri) 3nos\nkasuri methi\nmixer madhe halad 1/2 tsp\nnutmeg 1/2 grated\nsalt large chutki\nmutton\nsalt\nlemon juice\n5tbsp garlic ginger paste\n3 green chilis paste\nturmeric 1tsp\n1.5 tbsp kasmiri red chili powder\ncoriander powder 1tbsp\n2 tbsp biryani masala\npudhina dhaniya onion fried\n5tbsp oil onion wala\n300gms dahi"},"valorant/Valorant-vods":{"slug":"valorant/Valorant-vods","filePath":"valorant/Valorant vods.md","title":"Valorant vods","links":[],"tags":[],"content":"# Tarik Reacts to 100 Thieves vs FUT Esports | PLAYOFFS | VCT Masters Shanghai 2024"}}